{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20563d65",
   "metadata": {},
   "source": [
    "This notebook mainly contain the RNNs parts left out in the main notebook, simply copy paste the part into the RNN part of main notebook to be able to run it smoothly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7e48af",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "    1. GRU with summary only\n",
    "    2. LSTM with summary only\n",
    "    3. LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca00f5a5",
   "metadata": {},
   "source": [
    "# 1. GRU with summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0779e71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 407)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 407, 50)      736850      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 100)          45600       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            101         ['gru[0][0]']                    \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 17)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 18)           0           ['dense[0][0]',                  \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          4864        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          32896       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 64)           8256        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            65          ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 828,632\n",
      "Trainable params: 828,632\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_summary = Input(shape = (summary_pad_len, ))\n",
    "summary_embeddings = Embedding(summary_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(summary_glove_weights),\n",
    "                     input_length = summary_pad_len, trainable = True)(input_summary)\n",
    "GRU_summary = GRU(100)(summary_embeddings)\n",
    "dense_summary = Dense(1, activation =\"linear\")(GRU_summary)\n",
    "\n",
    "input_nontext = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "\n",
    "# Concatenate\n",
    "concat = concatenate([dense_summary, input_nontext])\n",
    "dense_full1 = Dense(256, activation = \"relu\")(concat)\n",
    "dense_full2 = Dense(128, activation=\"relu\")(dense_full1)\n",
    "dense_full3 = Dense(64, activation=\"relu\")(dense_full2)\n",
    "output_layer = Dense(1, activation = \"linear\")(dense_full3)\n",
    "\n",
    "model = Model(inputs=[input_summary, input_nontext], outputs = output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31d01261",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "260/260 [==============================] - 546s 2s/step - loss: 3383.4844 - mse: 3383.4844 - mae: 35.9039 - val_loss: 2777.6506 - val_mse: 2777.6506 - val_mae: 31.4482\n",
      "Epoch 2/25\n",
      "260/260 [==============================] - 529s 2s/step - loss: 2787.5581 - mse: 2787.5581 - mae: 32.6156 - val_loss: 2665.2039 - val_mse: 2665.2039 - val_mae: 31.7357\n",
      "Epoch 3/25\n",
      "260/260 [==============================] - 533s 2s/step - loss: 2425.9875 - mse: 2425.9875 - mae: 30.4488 - val_loss: 2870.3379 - val_mse: 2870.3379 - val_mae: 31.3374\n",
      "Epoch 4/25\n",
      "260/260 [==============================] - 503s 2s/step - loss: 2139.4868 - mse: 2139.4868 - mae: 28.5085 - val_loss: 2765.9397 - val_mse: 2765.9397 - val_mae: 30.6319\n",
      "Epoch 5/25\n",
      "260/260 [==============================] - ETA: 0s - loss: 1993.0309 - mse: 1993.0309 - mae: 27.5109Restoring model weights from the end of the best epoch: 2.\n",
      "260/260 [==============================] - 185s 713ms/step - loss: 1993.0309 - mse: 1993.0309 - mae: 27.5109 - val_loss: 2696.0759 - val_mse: 2696.0759 - val_mae: 31.1165\n",
      "Epoch 5: early stopping\n",
      "2297.6020896434784\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.01) \n",
    "\n",
    "model.compile(optimizer = opt, loss='mean_squared_error', metrics=['mse', 'mae'])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 25\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=0.01, restore_best_weights=True)]\n",
    "\n",
    "story = model.fit([padded_X_train_summary, X_train], y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs,\n",
    "                    verbose = 1,\n",
    "                    validation_split = 0.25,\n",
    "                  callbacks = callbacks) \n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4756d6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 30s 85ms/step\n"
     ]
    }
   ],
   "source": [
    "gru_sum_val_prediction = model.predict([padded_X_test_summary, X_test])\n",
    "gru_sum_val_prediction = pd.DataFrame(gru_sum_val_prediction, columns = [\"price\"])\n",
    "gru_sum_val_result = pd.concat([X_test_listing_id, gru_sum_val_prediction], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d3b2c",
   "metadata": {},
   "source": [
    "# 2. LSTM with summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d5bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_summary = Input(shape=(summary_pad_len, ))\n",
    "summary_embeddings = Embedding(summary_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer=Constant(summary_glove_weights),\n",
    "                     input_length=summary_pad_len, trainable=False)(input_summary)\n",
    "LSTM_text1 = LSTM(100, return_sequences=False)(summary_embeddings)\n",
    "dense_text = Dense(1, activation=\"linear\")(LSTM_text1)\n",
    "\n",
    "\n",
    "input_nontext = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# Concatenate\n",
    "concat = concatenate([dense_text, input_nontext])\n",
    "dense_full1 = Dense(256, activation = \"relu\")(concat)\n",
    "dense_full2 = Dense(128, activation=\"relu\")(dense_full1)\n",
    "output_layer = Dense(1, activation = \"linear\")(dense_full2)\n",
    "\n",
    "model = Model(inputs=[input_summary, input_nontext], outputs = output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "39e58726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "260/260 [==============================] - 264s 1s/step - loss: 2752.2649 - mse: 2752.2649 - mae: 32.4861 - val_loss: 2830.1797 - val_mse: 2830.1797 - val_mae: 33.0500\n",
      "Epoch 2/25\n",
      "260/260 [==============================] - 254s 977ms/step - loss: 2729.9072 - mse: 2729.9072 - mae: 32.4006 - val_loss: 2739.5403 - val_mse: 2739.5403 - val_mae: 31.5569\n",
      "Epoch 3/25\n",
      "260/260 [==============================] - 254s 977ms/step - loss: 2682.1990 - mse: 2682.1990 - mae: 32.0406 - val_loss: 2769.9661 - val_mse: 2769.9661 - val_mae: 33.9945\n",
      "Epoch 4/25\n",
      "260/260 [==============================] - 267s 1s/step - loss: 2668.2625 - mse: 2668.2625 - mae: 32.0252 - val_loss: 2823.0339 - val_mse: 2823.0339 - val_mae: 35.5169\n",
      "Epoch 5/25\n",
      "260/260 [==============================] - 273s 1s/step - loss: 2685.4473 - mse: 2685.4473 - mae: 32.1307 - val_loss: 2715.7258 - val_mse: 2715.7258 - val_mae: 33.0590\n",
      "Epoch 6/25\n",
      "260/260 [==============================] - 265s 1s/step - loss: 2654.8853 - mse: 2654.8853 - mae: 31.8843 - val_loss: 2755.8091 - val_mse: 2755.8091 - val_mae: 34.1552\n",
      "Epoch 7/25\n",
      "260/260 [==============================] - 258s 993ms/step - loss: 2620.7659 - mse: 2620.7659 - mae: 31.7134 - val_loss: 2713.2310 - val_mse: 2713.2310 - val_mae: 32.0879\n",
      "Epoch 8/25\n",
      "260/260 [==============================] - 266s 1s/step - loss: 2637.4363 - mse: 2637.4363 - mae: 31.9012 - val_loss: 2727.2319 - val_mse: 2727.2319 - val_mae: 33.1024\n",
      "Epoch 9/25\n",
      "260/260 [==============================] - 274s 1s/step - loss: 2622.7117 - mse: 2622.7117 - mae: 31.7437 - val_loss: 2704.6104 - val_mse: 2704.6104 - val_mae: 31.7451\n",
      "Epoch 10/25\n",
      "260/260 [==============================] - 263s 1s/step - loss: 2596.1692 - mse: 2596.1692 - mae: 31.5870 - val_loss: 2916.5630 - val_mse: 2916.5630 - val_mae: 35.5362\n",
      "Epoch 11/25\n",
      "260/260 [==============================] - 270s 1s/step - loss: 2590.2966 - mse: 2590.2966 - mae: 31.5420 - val_loss: 2748.6880 - val_mse: 2748.6880 - val_mae: 30.8856\n",
      "Epoch 12/25\n",
      "260/260 [==============================] - ETA: 0s - loss: 2590.4543 - mse: 2590.4543 - mae: 31.5311Restoring model weights from the end of the best epoch: 9.\n",
      "260/260 [==============================] - 264s 1s/step - loss: 2590.4543 - mse: 2590.4543 - mae: 31.5311 - val_loss: 2728.3989 - val_mse: 2728.3989 - val_mae: 31.2377\n",
      "Epoch 12: early stopping\n",
      "3171.3354494571686\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.01) \n",
    "\n",
    "model.compile(optimizer = opt, loss='mean_squared_error', metrics=['mse', 'mae'])\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 25\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=0.01, restore_best_weights=True)]\n",
    "\n",
    "story = model.fit([padded_X_train_summary, X_train], y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split = 0.25,\n",
    "               callbacks=callbacks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0ecd2ab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 44s 126ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11057.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>102.261246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>63.995358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.145638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.614307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>89.056229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>132.858215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>454.106262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price\n",
       "count  11057.000000\n",
       "mean     102.261246\n",
       "std       63.995358\n",
       "min        8.145638\n",
       "25%       50.614307\n",
       "50%       89.056229\n",
       "75%      132.858215\n",
       "max      454.106262"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_sum_val_prediction = model.predict([padded_X_test_summary, X_test])\n",
    "listing_id = pd.DataFrame(X_test_listing_id, columns = [\"listing_id\"])\n",
    "lstm_sum_val_prediction = pd.DataFrame(lstm_sum_val_prediction, columns = [\"price\"])\n",
    "lstm_sum_val_prediction.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561338cf",
   "metadata": {},
   "source": [
    "# 3. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6585d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = Input(shape=(name_pad_len, ))\n",
    "name_embeddings = Embedding(name_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(name_glove_weights),\n",
    "                     input_length = name_pad_len, trainable = True)(input_name)   # try trainable False\n",
    "LSTM_name1 = LSTM(25, return_sequences = False)(name_embeddings)\n",
    "dense_name = Dense(1, activation =\"linear\")(LSTM_name1)\n",
    "\n",
    "\n",
    "input_summary = Input(shape = (summary_pad_len, ))\n",
    "summary_embeddings = Embedding(summary_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(summary_glove_weights),\n",
    "                     input_length = summary_pad_len, trainable = True)(input_summary)\n",
    "LSTM_summary1 = LSTM(100, return_sequences = False)(summary_embeddings)\n",
    "dense_summary = Dense(1, activation =\"linear\")(LSTM_summary1)\n",
    "\n",
    "\n",
    "input_description = Input(shape = (description_pad_len, ))\n",
    "description_embeddings = Embedding(description_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(description_glove_weights),\n",
    "                     input_length = description_pad_len, trainable = True)(input_description)\n",
    "LSTM_description1 = LSTM(100, return_sequences = False)(description_embeddings)\n",
    "dense_description = Dense(1, activation=\"linear\")(LSTM_description1)\n",
    "\n",
    "\n",
    "input_amenities = Input(shape = (amenities_pad_len, ))\n",
    "amenities_embeddings = Embedding(amenities_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(amenities_glove_weights),\n",
    "                     input_length = description_pad_len, trainable = True)(input_amenities)\n",
    "LSTM_amenities1 = LSTM(100, return_sequences = False)(amenities_embeddings)\n",
    "dense_amenities = Dense(1, activation=\"linear\")(LSTM_amenities1)\n",
    "\n",
    "\n",
    "input_nontext = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "\n",
    "# Concatenate\n",
    "concat = concatenate([dense_name, dense_summary, dense_description, dense_amenities, input_nontext])\n",
    "# dense_full1 = Dense(256, activation = \"relu\")(concat)\n",
    "dense_full2 = Dense(128, activation=\"relu\")(concat) # (dense_full1)\n",
    "dense_full3 = Dense(64, activation=\"relu\")(dense_full2)\n",
    "output_layer = Dense(1, activation = \"linear\")(dense_full3)\n",
    "\n",
    "model = Model(inputs=[input_name, input_summary, input_description, input_amenities, input_nontext], outputs = output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "970647a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "260/260 [==============================] - 2955s 11s/step - loss: 3539.8206 - mse: 3539.8206 - mae: 36.9064 - val_loss: 2757.3503 - val_mse: 2757.3503 - val_mae: 31.3115\n",
      "Epoch 2/25\n",
      "260/260 [==============================] - 3015s 12s/step - loss: 2654.9353 - mse: 2654.9353 - mae: 31.6175 - val_loss: 2637.4202 - val_mse: 2637.4202 - val_mae: 30.5113\n",
      "Epoch 3/25\n",
      "260/260 [==============================] - 3143s 12s/step - loss: 2329.1807 - mse: 2329.1807 - mae: 29.7039 - val_loss: 2637.0850 - val_mse: 2637.0850 - val_mae: 32.2671\n",
      "Epoch 4/25\n",
      "260/260 [==============================] - 3083s 12s/step - loss: 2034.5288 - mse: 2034.5288 - mae: 27.5840 - val_loss: 2694.5303 - val_mse: 2694.5303 - val_mae: 32.3450\n",
      "Epoch 5/25\n",
      "260/260 [==============================] - 3401s 13s/step - loss: 1822.6223 - mse: 1822.6223 - mae: 26.1869 - val_loss: 2844.7207 - val_mse: 2844.7207 - val_mae: 31.6470\n",
      "Epoch 6/25\n",
      "260/260 [==============================] - ETA: 0s - loss: 1690.0753 - mse: 1690.0753 - mae: 25.2178 Restoring model weights from the end of the best epoch: 3.\n",
      "260/260 [==============================] - 3243s 12s/step - loss: 1690.0753 - mse: 1690.0753 - mae: 25.2178 - val_loss: 2961.9624 - val_mse: 2961.9624 - val_mae: 34.7676\n",
      "Epoch 6: early stopping\n",
      "18839.115295171738\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01) \n",
    "\n",
    "model.compile(optimizer = opt, loss='mean_squared_error', metrics=['mse', 'mae'])\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 25\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=0.01, restore_best_weights=True)]\n",
    "\n",
    "story = model.fit([padded_X_train_name, padded_X_train_summary, padded_X_train_description, padded_X_train_amenities, X_train], y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs,\n",
    "                    verbose = 1,\n",
    "                    validation_split = 0.25,\n",
    "                  callbacks = callbacks) \n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "8bccff45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 270s 781ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11057.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>108.701210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>70.819878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.272205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54.626667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>88.858482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>138.898926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>623.955505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price\n",
       "count  11057.000000\n",
       "mean     108.701210\n",
       "std       70.819878\n",
       "min       20.272205\n",
       "25%       54.626667\n",
       "50%       88.858482\n",
       "75%      138.898926\n",
       "max      623.955505"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_val_prediction = model.predict([padded_X_test_name, padded_X_test_summary, padded_X_test_description, padded_X_test_amenities, X_test])\n",
    "listing_id = pd.DataFrame(X_test_listing_id, columns = [\"listing_id\"])\n",
    "lstm_val_prediction = pd.DataFrame(lstm_val_prediction, columns = [\"price\"])\n",
    "lstm_val_prediction.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
