{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f7e48af",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "    1. Introduction\n",
    "    2. Data Loading and Cleaning\n",
    "    3. Text Analysis - Natural Language Processing\n",
    "        3.1 Sentiment Analysis using review data\n",
    "        3.2 Cleaning of text features\n",
    "        3.3 Data preparation for test data\n",
    "        3.4 Padding\n",
    "        3.5 Embedding\n",
    "    4. Model Evaluation\n",
    "        4.1 Linear Regression\n",
    "            4.1.1 Linear Regression without variable selection\n",
    "            4.1.2 Linear Regression with variable selection\n",
    "        4.2 Neural Network\n",
    "            4.2.1 Feedforward Neural Network\n",
    "            4.2.2 Gated Recurrent Unit\n",
    "            4.2.3 Bidirectional Long Short-Term Memory\n",
    "    5. Model Comparison and Selection\n",
    "    6. GRU application to Test Set\n",
    "    7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1315d84",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "The goal of this assignment is to predict Airbnb listings price in London using the techniques learnt in ADAMS (Natural Language Processing and Neural Networks) based on text and non-text features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d662a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from category_encoders import MEstimateEncoder\n",
    "from datetime import date\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import Input, concatenate, Dense, Embedding, LSTM, Bidirectional, GRU\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from spacy.lang.en import English\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from statistics import mode\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import activations, losses\n",
    "from tensorflow.keras import layers\n",
    "import emot_dictionary as emot\n",
    "import flair\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysentiment2 as ps\n",
    "import re\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import statsmodels.api as sm\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2500e7e1",
   "metadata": {},
   "source": [
    "# 2. Data Loading and cleaning\n",
    "\n",
    "First, the train and test data set as well as the additional reviews data set are loaded and the train data set is splitted into X_train, X_test, y_train and y_test respectively so that model selection could be performed based on X_test and y_test while only using the information from X_train and y_train. Prior to model selection, only information from X_train and y_train will be used for the analysis and prediction and after model selection, X_train and X_test, as well as y_train and y_test could be combined for the prediction task so that the data could be used more efficiently. The dataset can be found on: https://www.kaggle.com/competitions/adams-sose22/data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9ea219",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", sep=\",\", encoding = \"utf-8\")\n",
    "test = pd.read_csv(\"test.csv\", sep=\",\", encoding = \"utf-8\")\n",
    "review = pd.read_csv(\"reviews.csv\", sep = \",\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9f783c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(\"price\", axis = 1)\n",
    "y = train.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1116d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 934)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da4fd5b",
   "metadata": {},
   "source": [
    "After splitting the data, the descriptive statistics and misisng data are being looked into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8fa9a0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>space</th>\n",
       "      <th>description</th>\n",
       "      <th>experiences_offered</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>transit</th>\n",
       "      <th>house_rules</th>\n",
       "      <th>picture_url</th>\n",
       "      <th>host_id</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>listing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>44217</td>\n",
       "      <td>41841</td>\n",
       "      <td>30677</td>\n",
       "      <td>42827</td>\n",
       "      <td>44227</td>\n",
       "      <td>28614</td>\n",
       "      <td>28372</td>\n",
       "      <td>25564</td>\n",
       "      <td>44227</td>\n",
       "      <td>4.422700e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>33506.00000</td>\n",
       "      <td>33478.000000</td>\n",
       "      <td>33483.000000</td>\n",
       "      <td>33449.000000</td>\n",
       "      <td>33479.000000</td>\n",
       "      <td>33452.000000</td>\n",
       "      <td>33453.000000</td>\n",
       "      <td>44227</td>\n",
       "      <td>34340.000000</td>\n",
       "      <td>44227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>43381</td>\n",
       "      <td>39552</td>\n",
       "      <td>28769</td>\n",
       "      <td>41448</td>\n",
       "      <td>5</td>\n",
       "      <td>24635</td>\n",
       "      <td>25278</td>\n",
       "      <td>20153</td>\n",
       "      <td>43650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Double room</td>\n",
       "      <td>Featured in The New York Times, The Wall Stree...</td>\n",
       "      <td>Situated in an excellent central location. Tow...</td>\n",
       "      <td>My Luxury Two Bedroom apartment is located min...</td>\n",
       "      <td>none</td>\n",
       "      <td>Conveniently located in Maida Vale one of Lond...</td>\n",
       "      <td>Transport links are excellent with convenient ...</td>\n",
       "      <td>- The lead guest will be required to sign an O...</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/d029c664-c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JYEVUNA9PH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>23</td>\n",
       "      <td>104</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>43366</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>167</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.818925e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>92.54062</td>\n",
       "      <td>9.504391</td>\n",
       "      <td>9.262880</td>\n",
       "      <td>9.623128</td>\n",
       "      <td>9.653693</td>\n",
       "      <td>9.538682</td>\n",
       "      <td>9.264371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.171109</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.018841e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>10.07104</td>\n",
       "      <td>0.979810</td>\n",
       "      <td>1.137731</td>\n",
       "      <td>0.894640</td>\n",
       "      <td>0.872253</td>\n",
       "      <td>0.813971</td>\n",
       "      <td>1.032474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.362198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.697000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.513013e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>90.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.816502e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>96.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.449555e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.256719e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.040000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name                                            summary  \\\n",
       "count         44217                                              41841   \n",
       "unique        43381                                              39552   \n",
       "top     Double room  Featured in The New York Times, The Wall Stree...   \n",
       "freq             23                                                104   \n",
       "mean            NaN                                                NaN   \n",
       "std             NaN                                                NaN   \n",
       "min             NaN                                                NaN   \n",
       "25%             NaN                                                NaN   \n",
       "50%             NaN                                                NaN   \n",
       "75%             NaN                                                NaN   \n",
       "max             NaN                                                NaN   \n",
       "\n",
       "                                                    space  \\\n",
       "count                                               30677   \n",
       "unique                                              28769   \n",
       "top     Situated in an excellent central location. Tow...   \n",
       "freq                                                   15   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                              description experiences_offered  \\\n",
       "count                                               42827               44227   \n",
       "unique                                              41448                   5   \n",
       "top     My Luxury Two Bedroom apartment is located min...                none   \n",
       "freq                                                   14               43366   \n",
       "mean                                                  NaN                 NaN   \n",
       "std                                                   NaN                 NaN   \n",
       "min                                                   NaN                 NaN   \n",
       "25%                                                   NaN                 NaN   \n",
       "50%                                                   NaN                 NaN   \n",
       "75%                                                   NaN                 NaN   \n",
       "max                                                   NaN                 NaN   \n",
       "\n",
       "                                    neighborhood_overview  \\\n",
       "count                                               28614   \n",
       "unique                                              24635   \n",
       "top     Conveniently located in Maida Vale one of Lond...   \n",
       "freq                                                   32   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                                  transit  \\\n",
       "count                                               28372   \n",
       "unique                                              25278   \n",
       "top     Transport links are excellent with convenient ...   \n",
       "freq                                                   36   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                              house_rules  \\\n",
       "count                                               25564   \n",
       "unique                                              20153   \n",
       "top     - The lead guest will be required to sign an O...   \n",
       "freq                                                  167   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                              picture_url       host_id  ...  \\\n",
       "count                                               44227  4.422700e+04  ...   \n",
       "unique                                              43650           NaN  ...   \n",
       "top     https://a0.muscache.com/im/pictures/d029c664-c...           NaN  ...   \n",
       "freq                                                    6           NaN  ...   \n",
       "mean                                                  NaN  8.818925e+07  ...   \n",
       "std                                                   NaN  9.018841e+07  ...   \n",
       "min                                                   NaN  2.697000e+03  ...   \n",
       "25%                                                   NaN  1.513013e+07  ...   \n",
       "50%                                                   NaN  4.816502e+07  ...   \n",
       "75%                                                   NaN  1.449555e+08  ...   \n",
       "max                                                   NaN  3.256719e+08  ...   \n",
       "\n",
       "       review_scores_rating review_scores_accuracy review_scores_cleanliness  \\\n",
       "count           33506.00000           33478.000000              33483.000000   \n",
       "unique                  NaN                    NaN                       NaN   \n",
       "top                     NaN                    NaN                       NaN   \n",
       "freq                    NaN                    NaN                       NaN   \n",
       "mean               92.54062               9.504391                  9.262880   \n",
       "std                10.07104               0.979810                  1.137731   \n",
       "min                20.00000               2.000000                  2.000000   \n",
       "25%                90.00000               9.000000                  9.000000   \n",
       "50%                96.00000              10.000000                 10.000000   \n",
       "75%               100.00000              10.000000                 10.000000   \n",
       "max               100.00000              10.000000                 10.000000   \n",
       "\n",
       "       review_scores_checkin  review_scores_communication  \\\n",
       "count           33449.000000                 33479.000000   \n",
       "unique                   NaN                          NaN   \n",
       "top                      NaN                          NaN   \n",
       "freq                     NaN                          NaN   \n",
       "mean                9.623128                     9.653693   \n",
       "std                 0.894640                     0.872253   \n",
       "min                 2.000000                     2.000000   \n",
       "25%                10.000000                    10.000000   \n",
       "50%                10.000000                    10.000000   \n",
       "75%                10.000000                    10.000000   \n",
       "max                10.000000                    10.000000   \n",
       "\n",
       "       review_scores_location review_scores_value  \\\n",
       "count            33452.000000        33453.000000   \n",
       "unique                    NaN                 NaN   \n",
       "top                       NaN                 NaN   \n",
       "freq                      NaN                 NaN   \n",
       "mean                 9.538682            9.264371   \n",
       "std                  0.813971            1.032474   \n",
       "min                  2.000000            2.000000   \n",
       "25%                  9.000000            9.000000   \n",
       "50%                 10.000000            9.000000   \n",
       "75%                 10.000000           10.000000   \n",
       "max                 10.000000           10.000000   \n",
       "\n",
       "                cancellation_policy reviews_per_month  listing_id  \n",
       "count                         44227      34340.000000       44227  \n",
       "unique                            8               NaN       44227  \n",
       "top     strict_14_with_grace_period               NaN  JYEVUNA9PH  \n",
       "freq                          19240               NaN           1  \n",
       "mean                            NaN          1.171109         NaN  \n",
       "std                             NaN          1.362198         NaN  \n",
       "min                             NaN          0.010000         NaN  \n",
       "25%                             NaN          0.240000         NaN  \n",
       "50%                             NaN          0.730000         NaN  \n",
       "75%                             NaN          1.580000         NaN  \n",
       "max                             NaN         22.040000         NaN  \n",
       "\n",
       "[11 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2bc7102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(X_train.isnull(), cbar = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba7dbd4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                           0.000226\n",
       "summary                        0.053949\n",
       "space                          0.306374\n",
       "description                    0.031655\n",
       "experiences_offered            0.000000\n",
       "neighborhood_overview          0.353020\n",
       "transit                        0.358491\n",
       "house_rules                    0.421982\n",
       "picture_url                    0.000000\n",
       "host_id                        0.000000\n",
       "host_since                     0.002035\n",
       "host_response_time             0.320551\n",
       "host_response_rate             0.320551\n",
       "host_is_superhost              0.002035\n",
       "host_total_listings_count      0.002035\n",
       "host_has_profile_pic           0.002035\n",
       "host_identity_verified         0.002035\n",
       "neighbourhood                  0.002623\n",
       "neighbourhood_cleansed         0.000000\n",
       "zipcode                        0.022905\n",
       "latitude                       0.000000\n",
       "longitude                      0.000000\n",
       "property_type                  0.000000\n",
       "room_type                      0.000000\n",
       "accommodates                   0.000000\n",
       "bathrooms                      0.001289\n",
       "bedrooms                       0.001085\n",
       "beds                           0.004839\n",
       "bed_type                       0.000000\n",
       "amenities                      0.000000\n",
       "guests_included                0.000000\n",
       "review_scores_rating           0.242408\n",
       "review_scores_accuracy         0.243042\n",
       "review_scores_cleanliness      0.242929\n",
       "review_scores_checkin          0.243697\n",
       "review_scores_communication    0.243019\n",
       "review_scores_location         0.243629\n",
       "review_scores_value            0.243607\n",
       "cancellation_policy            0.000000\n",
       "reviews_per_month              0.223551\n",
       "listing_id                     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()/X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605eeb89",
   "metadata": {},
   "source": [
    "Upon inspecting the null values in the data set, noticed that space, neighnorhood_overview, transit, house_rules, host_response_time, host_response_rate, and several reviews related variables have about 20 - 40% missing data and so it is not a good idea to predict result based on these variables. They are therefore excluded from the data sets.\n",
    "\n",
    "Several other variables such as image and geographical data are excluded because the type of data would not be analysed here. 'neighbourhood_cleansed' are exlcuded because it is similar to 'neighbourhood' and contain less information. 'host_id' and 'listing_id' are excluded because they are not relevant for price prediction. listing_id is saved to be used later as key id for inner join with the result from sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26deedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rate = X_train.isnull().sum()/X_train.shape[0]\n",
    "missing_drop = list(missing_rate[missing_rate > 0.2].index)\n",
    "X_train = X_train.drop(missing_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01eca603",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [X_train, X_test, y_train, y_test, test]:\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train_listing_id = X_train.listing_id \n",
    "X_test_listing_id = X_test.listing_id\n",
    "test_listing_id = test.listing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "725524ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop([\"picture_url\", \"host_id\", \"neighbourhood_cleansed\", \"zipcode\", \"latitude\",\n",
    "                    \"longitude\", \"listing_id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc154e7",
   "metadata": {},
   "source": [
    "For text and categorical variables, the missing values could be filled in as a new category or text: 'Missing', while mode is used to fill in the missing value for the variable \"host_since\" (date variable), 'host_total_listings_count', 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'bathrooms', 'bedrooms', 'beds'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2e9adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_col in ['name', 'summary', 'description', 'neighbourhood', 'bed_type', 'amenities']:\n",
    "    \n",
    "    X_train[text_col].fillna('Missing', inplace = True, downcast = 'infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb5b8b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['host_since', 'host_total_listings_count','host_is_superhost','host_has_profile_pic', \n",
    "            'host_identity_verified', 'bathrooms', 'bedrooms', 'beds']:\n",
    "     X_train.loc[X_train[col].isnull() == True, col] = mode(X_train[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3124716f",
   "metadata": {},
   "source": [
    "Another quick overview of the data set reveals that several of the variables are not in appropriate data type, and thus they are being transformed into suitable data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7e26d0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44227 entries, 0 to 44226\n",
      "Data columns (total 20 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   name                       44227 non-null  object \n",
      " 1   summary                    44227 non-null  object \n",
      " 2   description                44227 non-null  object \n",
      " 3   experiences_offered        44227 non-null  object \n",
      " 4   host_since                 44227 non-null  object \n",
      " 5   host_is_superhost          44227 non-null  object \n",
      " 6   host_total_listings_count  44227 non-null  float64\n",
      " 7   host_has_profile_pic       44227 non-null  object \n",
      " 8   host_identity_verified     44227 non-null  object \n",
      " 9   neighbourhood              44227 non-null  object \n",
      " 10  property_type              44227 non-null  object \n",
      " 11  room_type                  44227 non-null  object \n",
      " 12  accommodates               44227 non-null  int64  \n",
      " 13  bathrooms                  44227 non-null  float64\n",
      " 14  bedrooms                   44227 non-null  float64\n",
      " 15  beds                       44227 non-null  float64\n",
      " 16  bed_type                   44227 non-null  object \n",
      " 17  amenities                  44227 non-null  object \n",
      " 18  guests_included            44227 non-null  int64  \n",
      " 19  cancellation_policy        44227 non-null  object \n",
      "dtypes: float64(4), int64(2), object(14)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e0377fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>experiences_offered</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>amenities</th>\n",
       "      <th>guests_included</th>\n",
       "      <th>cancellation_policy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>44227</td>\n",
       "      <td>44227</td>\n",
       "      <td>44227</td>\n",
       "      <td>44227</td>\n",
       "      <td>44227</td>\n",
       "      <td>44227</td>\n",
       "      <td>44227.000000</td>\n",
       "      <td>44227</td>\n",
       "      <td>44227</td>\n",
       "      <td>44227</td>\n",
       "      <td>44227</td>\n",
       "      <td>44227</td>\n",
       "      <td>44227.000000</td>\n",
       "      <td>44227.000000</td>\n",
       "      <td>44227.000000</td>\n",
       "      <td>44227.000000</td>\n",
       "      <td>44227</td>\n",
       "      <td>44227</td>\n",
       "      <td>44227.000000</td>\n",
       "      <td>44227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>43382</td>\n",
       "      <td>39553</td>\n",
       "      <td>41449</td>\n",
       "      <td>5</td>\n",
       "      <td>3415</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>40696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Double room</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>none</td>\n",
       "      <td>2015-05-21</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>City of Westminster</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>23</td>\n",
       "      <td>2386</td>\n",
       "      <td>1400</td>\n",
       "      <td>43366</td>\n",
       "      <td>415</td>\n",
       "      <td>37617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44099</td>\n",
       "      <td>28404</td>\n",
       "      <td>2615</td>\n",
       "      <td>29629</td>\n",
       "      <td>24386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43882</td>\n",
       "      <td>174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.470256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.127547</td>\n",
       "      <td>1.283277</td>\n",
       "      <td>1.370995</td>\n",
       "      <td>1.704886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.573383</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.016019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.924169</td>\n",
       "      <td>0.569279</td>\n",
       "      <td>0.855693</td>\n",
       "      <td>1.220817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.263417</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1321.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  summary description experiences_offered  host_since  \\\n",
       "count         44227    44227       44227               44227       44227   \n",
       "unique        43382    39553       41449                   5        3415   \n",
       "top     Double room  Missing     Missing                none  2015-05-21   \n",
       "freq             23     2386        1400               43366         415   \n",
       "mean            NaN      NaN         NaN                 NaN         NaN   \n",
       "std             NaN      NaN         NaN                 NaN         NaN   \n",
       "min             NaN      NaN         NaN                 NaN         NaN   \n",
       "25%             NaN      NaN         NaN                 NaN         NaN   \n",
       "50%             NaN      NaN         NaN                 NaN         NaN   \n",
       "75%             NaN      NaN         NaN                 NaN         NaN   \n",
       "max             NaN      NaN         NaN                 NaN         NaN   \n",
       "\n",
       "       host_is_superhost  host_total_listings_count host_has_profile_pic  \\\n",
       "count              44227               44227.000000                44227   \n",
       "unique                 2                        NaN                    2   \n",
       "top                    f                        NaN                    t   \n",
       "freq               37617                        NaN                44099   \n",
       "mean                 NaN                  20.470256                  NaN   \n",
       "std                  NaN                 116.016019                  NaN   \n",
       "min                  NaN                   0.000000                  NaN   \n",
       "25%                  NaN                   1.000000                  NaN   \n",
       "50%                  NaN                   1.000000                  NaN   \n",
       "75%                  NaN                   5.000000                  NaN   \n",
       "max                  NaN                1321.000000                  NaN   \n",
       "\n",
       "       host_identity_verified        neighbourhood property_type  \\\n",
       "count                   44227                44227         44227   \n",
       "unique                      2                  150            37   \n",
       "top                         f  City of Westminster     Apartment   \n",
       "freq                    28404                 2615         29629   \n",
       "mean                      NaN                  NaN           NaN   \n",
       "std                       NaN                  NaN           NaN   \n",
       "min                       NaN                  NaN           NaN   \n",
       "25%                       NaN                  NaN           NaN   \n",
       "50%                       NaN                  NaN           NaN   \n",
       "75%                       NaN                  NaN           NaN   \n",
       "max                       NaN                  NaN           NaN   \n",
       "\n",
       "              room_type  accommodates     bathrooms      bedrooms  \\\n",
       "count             44227  44227.000000  44227.000000  44227.000000   \n",
       "unique                4           NaN           NaN           NaN   \n",
       "top     Entire home/apt           NaN           NaN           NaN   \n",
       "freq              24386           NaN           NaN           NaN   \n",
       "mean                NaN      3.127547      1.283277      1.370995   \n",
       "std                 NaN      1.924169      0.569279      0.855693   \n",
       "min                 NaN      1.000000      0.000000      0.000000   \n",
       "25%                 NaN      2.000000      1.000000      1.000000   \n",
       "50%                 NaN      2.000000      1.000000      1.000000   \n",
       "75%                 NaN      4.000000      1.500000      2.000000   \n",
       "max                 NaN     16.000000     11.000000     19.000000   \n",
       "\n",
       "                beds  bed_type amenities  guests_included  \\\n",
       "count   44227.000000     44227     44227     44227.000000   \n",
       "unique           NaN         5     40696              NaN   \n",
       "top              NaN  Real Bed        {}              NaN   \n",
       "freq             NaN     43882       174              NaN   \n",
       "mean        1.704886       NaN       NaN         1.573383   \n",
       "std         1.220817       NaN       NaN         1.263417   \n",
       "min         0.000000       NaN       NaN         1.000000   \n",
       "25%         1.000000       NaN       NaN         1.000000   \n",
       "50%         1.000000       NaN       NaN         1.000000   \n",
       "75%         2.000000       NaN       NaN         2.000000   \n",
       "max        21.000000       NaN       NaN        46.000000   \n",
       "\n",
       "                cancellation_policy  \n",
       "count                         44227  \n",
       "unique                            8  \n",
       "top     strict_14_with_grace_period  \n",
       "freq                          19240  \n",
       "mean                            NaN  \n",
       "std                             NaN  \n",
       "min                             NaN  \n",
       "25%                             NaN  \n",
       "50%                             NaN  \n",
       "75%                             NaN  \n",
       "max                             NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63b47d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for boo in ('host_is_superhost','host_has_profile_pic', 'host_identity_verified'):\n",
    "    X_train[boo] = X_train[boo].map({'t': 1, 'f': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "754dc1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ('host_total_listings_count', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'guests_included'):\n",
    "    X_train[i] = X_train[i].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71de1361",
   "metadata": {},
   "source": [
    "M-estimate encoder is used to encode the categorical variables into numeric values. M-estimate encoding is used over one-hot encoding is because it helps to keep the dimension of the data low while one-hot encoding might increase the column numbers enomoursly. An M-estimate encoding with regularization parameter of zero is equivalent to mean encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea7d3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = MEstimateEncoder(cols = ['experiences_offered', 'neighbourhood', 'property_type', \n",
    "          'room_type', 'bed_type', 'cancellation_policy'], m = 0)\n",
    "\n",
    "encoder.fit(X_train, y_train)\n",
    "X_train = encoder.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f8c644",
   "metadata": {},
   "source": [
    "host_since column is converted to date instead of string data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38342b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.host_since = pd.to_datetime(X_train.host_since)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be0f14",
   "metadata": {},
   "source": [
    "Airbnb is launched on 11th August 2008, and so that's the earliest day someone could be a host. The host_since variable could be transform into how many days after the launch it is launched so that it works better with neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a0081cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch = date(2018, 11, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a49ed21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_from_start(date, start):\n",
    "    delta = start - date.date()\n",
    "    \n",
    "    return(delta.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2aa5f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"host_since_days_after_launch\"] = X_train.host_since.apply(days_from_start, args = (launch, ))\n",
    "X_train = X_train.drop('host_since', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2134a2",
   "metadata": {},
   "source": [
    "# 3. Text Analysis - Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89752f03",
   "metadata": {},
   "source": [
    "## 3.1 Sentiment Analysis using reviews data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf9cd61",
   "metadata": {},
   "source": [
    "Looking at the review data, there are some non-english reviews and these should be removed because they are considered as noise for English text based model. This could be done by spacy_langdetect's LanguageDetector which gives the probability that a text is of a given language. First all rows with null entry for comments are removed and then a function that replaced the comments with whether they are english, non-english or Unknown/not proper language are applied to the comments column. The text will be kept unchanged if it is predicted to be in english while being replaced by 'Non-english' or 'Unknown or not proper language' otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba5166d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = review[review.comments.notnull()] # remove all rows with empty comments entry\n",
    "review.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680c9680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_langdetect.spacy_langdetect.LanguageDetector at 0x18670d68fd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "@Language.factory('language_detector')\n",
    "def language_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "nlp.add_pipe('language_detector', last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f46b8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_det(df, cols, return_language_only = True):\n",
    "    '''\n",
    "    A function that predicts the language of the text and replace it with 'Unknown or not proper language', \n",
    "    'Non-english' or keep the english text if they are unknown language, non-english language or english respectively.\n",
    "    '''\n",
    "    for col in cols:\n",
    "        for i, text in zip(df.index, df[col]):\n",
    "            a = nlp(text)\n",
    "            language = a._.language.get('language')\n",
    "            \n",
    "            if return_language_only == True:\n",
    "                df.loc[i, col] = language\n",
    "            \n",
    "            elif return_language_only == False:\n",
    "                if language == 'UNKNOWN':\n",
    "                    df.loc[i, col] = 'Unknown or not proper language'\n",
    "                elif (language != 'en' and language != 'UNKNOWN'):\n",
    "                    df.loc[i, col] = \"Non-english\"\n",
    "                elif language == 'en': # Do nothing if it is english\n",
    "                    df.loc[i, col] = text\n",
    "                        \n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91a314af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lan = review.copy()\n",
    "lan = language_det(review, [\"comments\"], return_language = True) # apply the function to the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acc697ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en         86.048840\n",
       "fr          4.738174\n",
       "es          2.392657\n",
       "de          1.602572\n",
       "it          1.146234\n",
       "ko          0.816318\n",
       "zh-cn       0.630873\n",
       "pt          0.419587\n",
       "nl          0.325241\n",
       "ro          0.213884\n",
       "UNKNOWN     0.167004\n",
       "ca          0.155316\n",
       "so          0.143693\n",
       "af          0.130317\n",
       "ja          0.114734\n",
       "ru          0.111033\n",
       "da          0.110903\n",
       "cs          0.109344\n",
       "pl          0.095579\n",
       "sv          0.086164\n",
       "no          0.075385\n",
       "tl          0.046036\n",
       "fi          0.043244\n",
       "cy          0.037595\n",
       "hu          0.034998\n",
       "id          0.030583\n",
       "tr          0.022012\n",
       "el          0.018765\n",
       "sk          0.017467\n",
       "vi          0.016558\n",
       "sw          0.016428\n",
       "hr          0.016298\n",
       "et          0.014999\n",
       "zh-tw       0.011818\n",
       "he          0.011558\n",
       "ar          0.009285\n",
       "sl          0.006883\n",
       "th          0.003312\n",
       "sq          0.002013\n",
       "lv          0.002013\n",
       "lt          0.001948\n",
       "bg          0.001234\n",
       "uk          0.000519\n",
       "mk          0.000325\n",
       "fa          0.000130\n",
       "hi          0.000065\n",
       "ur          0.000065\n",
       "Name: comments, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lan.comments.value_counts()/lan.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c75ea",
   "metadata": {},
   "source": [
    "About 86% of the comments are english and the rest are non-english. All non-english comments are discarded as they are considered as noise for english-based sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b07ee3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_en = review[lan.comments == 'en']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b042068",
   "metadata": {},
   "source": [
    "Next a text cleaning function is created and applied to the comments column that:\n",
    "1. Remove html contents\n",
    "2. Remove white spaces\n",
    "3. Convert emoticons into meaningful text\n",
    "4. Remove punctuations, casing and non-alphanumeric characters\n",
    "5. Remove english-stopwords\n",
    "6. Lemmatize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4d7e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Helper function that calls the POS tagger for an input word and return a code that can be used for lemmatization\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()  \n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def remove_whitespace(text):\n",
    "    \"\"\" Function to remove whitespaces. \"\"\"\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def convert_emoticons(text):\n",
    "    \"\"\" Function to convert emoticons into a text that reflects their meaning. \"\"\"\n",
    "    EMOTICONS = emot.EMOTICONS()\n",
    "    for i in EMOTICONS:\n",
    "        text = text.replace(i, EMOTICONS[i])\n",
    "    return text\n",
    "\n",
    "def remove_punctuation_and_casing(text):\n",
    "    \"\"\"\n",
    "    Function to remove the punctuation, upper casing and words that include\n",
    "    non-alphanumeric characters.\n",
    "    \"\"\"\n",
    "    chars = '!\\\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'\n",
    "    text = text.translate(str.maketrans(chars, ' ' * len(chars)))\n",
    "    return ' '.join([word.lower() for word in text.split() if word.isalpha()])\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\" Function that removes english stopwords. \"\"\"\n",
    "    return ' '.join([word for word in str(text).split() if word not in english_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4897cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    \"\"\"\n",
    "    Function that remove html contents, white spaces, punctuations, casing, non-alphanumeric characters, english stopwords, \n",
    "    convert emoticons into meaningful text and lemmatize words.\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = BeautifulSoup(text).get_text()\n",
    "    text = remove_whitespace(text)\n",
    "    text = convert_emoticons(text)\n",
    "    text = remove_punctuation_and_casing(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = ' '.join([lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in text.split()])\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54da656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cols(df, cols):\n",
    "    '''\n",
    "    A function that apply text_cleaning to selected columns of the data frame. \n",
    "    '''\n",
    "    \n",
    "    for col in cols:\n",
    "        for i, text in zip(df.index, df[col]):\n",
    "            df.loc[i, col] = text_cleaning(text)\n",
    "    \n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9f7590d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "review_en = clean_cols(review_en, [\"comments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f6284c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_cleaned = review_en.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c979a1cb",
   "metadata": {},
   "source": [
    "After the comments are cleaned, pysentiment2 package is used to predict the sentiment of each comments. The average sentiment of each listing_id is calculated and joint with all train and test data using listing_id as the key values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f3f8562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = ps.HIV4()\n",
    "\n",
    "def get_sentiment_score(text):\n",
    "    score = round(dc.get_score(dc.tokenize(text))['Polarity'], 2)\n",
    "    return score\n",
    "\n",
    "review_cleaned['sentiment'] = review_cleaned.comments.apply(get_sentiment_score)\n",
    "\n",
    "review_cleaned['average_sentiment'] = review_cleaned.groupby(['listing_id'])['sentiment'].transform(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3c59fcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_cleaned = review_cleaned.drop(['reviewer_id', 'comments', 'review_id', 'sentiment'], axis = 1)\n",
    "review_cleaned = review_cleaned.drop_duplicates(subset = 'listing_id') \n",
    "# remove all duplicates to get unique listing_id matches with their average sentiment scores\n",
    "\n",
    "review_cleaned.to_csv(\"C:/Users/felix/OneDrive/Desktop/ADAMS kaggle/sentiment_cleaned.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f4a03f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [X_train, X_test, test]:\n",
    "    df.loc[df[\"average_sentiment\"].isnull() == True, \"average_sentiment\"] = np.mean(review_cleaned[\"average_sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a8e263bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, X_train_listing_id], axis = 1)\n",
    "X_test = pd.concat([X_test, X_test_listing_id], axis = 1)\n",
    "test = pd.concat([test, test_listing_id], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9efd8989",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [X_train, X_test, test]:\n",
    "    df = pd.merge(df, review_cleaned, how = \"left\", on = 'listing_id')\n",
    "    df = df.drop('listing_id', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5619470",
   "metadata": {},
   "source": [
    "## 3.2 Cleaning of text features\n",
    "\n",
    "Being done with sentiment analysis on review data, now the txt features in the main train data set could be worked on. Firstly, the functions created earlier is used to predict the languages of the text entries and text cleaning is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66e6dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = language_det(X_train, [\"name\", \"summary\", \"description\", \"amenities\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e55316b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = [\"name\", \"summary\", \"description\", \"amenities\"]\n",
    "X_train = clean_cols(X_train, text_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ec2eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the empty entry after text cleaning with an empty space\n",
    "\n",
    "for text_col in ['name', 'summary', 'description', 'amenities']:\n",
    "            X_train[text_col].fillna(' ', inplace = True, downcast = 'infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8947e7",
   "metadata": {},
   "source": [
    "## 3.3 Data preparation for test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3fa278",
   "metadata": {},
   "source": [
    "Create a function that apply all above steps of variable selections, replacing missing values and data preparations based on the information from train dataset and use it on on test and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3c209e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(df):\n",
    "    df = df.drop(missing_drop, axis = 1)\n",
    "    \n",
    "    for text_col in ['name', 'summary', 'description', 'neighbourhood', 'neighbourhood_cleansed', 'bed_type', 'amenities']:\n",
    "        df[text_col].fillna('Missing', inplace = True, downcast = 'infer')\n",
    "    \n",
    "    df = df.drop(['picture_url', 'host_id', 'neighbourhood_cleansed', 'zipcode', 'latitude',\n",
    "                    'longitude', 'listing_id'], axis = 1)\n",
    "    \n",
    "    for col in ['host_since', 'host_total_listings_count','host_is_superhost','host_has_profile_pic', \n",
    "            'host_identity_verified', 'bathrooms', 'bedrooms', 'beds']:\n",
    "        df.loc[df[col].isnull() == True, col] = mode(X_train[col])\n",
    "        \n",
    "    for i in ('host_total_listings_count', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'guests_included'):\n",
    "        df[i] = df[i].astype(\"int\")\n",
    "        \n",
    "    for boo in ('host_is_superhost','host_has_profile_pic', 'host_identity_verified'):\n",
    "        df[boo] = df[boo].map({'t': 1, 'f': 0})\n",
    "    \n",
    "    df = encoder.transform(df)\n",
    "    \n",
    "    df.host_since = pd.to_datetime(df.host_since)\n",
    "    \n",
    "    df[\"host_since_days_after_launch\"] = df.host_since.apply(days_from_start, args = (launch, ))\n",
    "    \n",
    "    df = df.drop('host_since', axis = 1)\n",
    "    \n",
    "    df = language_det(df, [\"name\", \"summary\", \"description\", \"amenities\"])\n",
    "    \n",
    "    df = clean_cols(df, text_cols)\n",
    "    \n",
    "    for df in [X_test, test]: \n",
    "        for text_col in ['name', 'summary', 'description', 'amenities']:\n",
    "            df[text_col].fillna(' ', inplace = True, downcast = 'infer')\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e3e3275a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test = data_preparation(X_test)\n",
    "test = data_preparation(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762ee17e",
   "metadata": {},
   "source": [
    "For texts data, they will be used separately from numeric features in prediciton, and thus must be separated from training data as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7966ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = X_train[['name', 'summary', 'description', 'amenities']]\n",
    "X_test_text = X_test[['name', 'summary', 'description', 'amenities']]\n",
    "test_text = test[['name', 'summary', 'description', 'amenities']]\n",
    "\n",
    "for df in [X_train, X_test, test]:\n",
    "    df = df.drop(['name', 'summary', 'description', 'amenities'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd85e4c6",
   "metadata": {},
   "source": [
    "## 3.4 Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ad960",
   "metadata": {},
   "source": [
    "For padding length of each text features, the cumulative distribution function (CDF) of each text feature is plotted and the first ending value of histogram bins that exceeds 90% is taken as the upper bound of pad length. After plotting the CDF of each text feature and the pas length is determined, each word is tokenized and each entry is padded to the decided length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2be97b3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name       CDF\n",
      "0   21.6  0.218034\n",
      "1   42.2  0.884505\n",
      "2   62.8  0.998892\n",
      "3   83.4  0.999706\n",
      "4  104.0  0.999932\n",
      "5  124.6  0.999955\n",
      "6  145.2  0.999955\n",
      "7  165.8  0.999955\n",
      "8  186.4  0.999977\n",
      "9  207.0  1.000000 \n",
      "\n",
      "   summary       CDF\n",
      "0     83.8  0.120741\n",
      "1    164.6  0.283153\n",
      "2    245.4  0.520248\n",
      "3    326.2  0.781627\n",
      "4    407.0  0.986750\n",
      "5    487.8  0.991295\n",
      "6    568.6  0.992335\n",
      "7    649.4  0.994641\n",
      "8    730.2  0.998349\n",
      "9    811.0  1.000000 \n",
      "\n",
      "   description       CDF\n",
      "0         92.7  0.063355\n",
      "1        184.4  0.125489\n",
      "2        276.1  0.186018\n",
      "3        367.8  0.266647\n",
      "4        459.5  0.315237\n",
      "5        551.2  0.365139\n",
      "6        642.9  0.541773\n",
      "7        734.6  0.929613\n",
      "8        826.3  0.997829\n",
      "9        918.0  1.000000 \n",
      "\n",
      "   amenities       CDF\n",
      "0      139.7  0.215479\n",
      "1      270.4  0.655550\n",
      "2      401.1  0.904922\n",
      "3      531.8  0.983946\n",
      "4      662.5  0.996179\n",
      "5      793.2  0.998440\n",
      "6      923.9  0.999299\n",
      "7     1054.6  0.999774\n",
      "8     1185.3  0.999932\n",
      "9     1316.0  1.000000 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'name'}>,\n",
       "        <AxesSubplot:title={'center':'summary'}>],\n",
       "       [<AxesSubplot:title={'center':'description'}>,\n",
       "        <AxesSubplot:title={'center':'amenities'}>]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length = X_train_text.copy()\n",
    "\n",
    "for col in length.columns:\n",
    "    length[col] = length[col].apply(len)\n",
    "\n",
    "for col in length.columns:\n",
    "    d, v = np.histogram(length[col])\n",
    "    c = np.cumsum(d)/length.shape[0]\n",
    "    print (pd.DataFrame({col : v[1:], 'CDF' : c}), \"\\n\") \n",
    "\n",
    "    # Exclude the starting value of bins so that the length of density and values match, \n",
    "    # the resulting data frame is in the format of: (ending value, CDF)\n",
    "\n",
    "length.hist(density = True, cumulative = True, label='CDF',\n",
    "             histtype = 'step', alpha=0.8, color = 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e723b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_pad_len = 63\n",
    "summary_pad_len = 407\n",
    "description_pad_len = 735\n",
    "amenities_pad_len = 402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a599714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name\n",
    "name_tokenizer = Tokenizer(oov_token=1, filters='!\"#$%&()*+,-.:;<=>?@[\\\\]^`{|}~\\t\\n', lower=False)\n",
    "name_tokenizer.fit_on_texts(X_train_text.name)\n",
    "X_train_name_tokens = name_tokenizer.texts_to_sequences(X_train_text.name)\n",
    "\n",
    "X_test_name_tokens = name_tokenizer.texts_to_sequences(X_test_text.name)\n",
    "test_name_tokens = name_tokenizer.texts_to_sequences(test_text.name)\n",
    "\n",
    "# summary\n",
    "summary_tokenizer = Tokenizer(oov_token=1, filters='!\"#$%&()*+,-.:;<=>?@[\\\\]^`{|}~\\t\\n', lower=False)\n",
    "summary_tokenizer.fit_on_texts(X_train_text.summary)\n",
    "X_train_summary_tokens = summary_tokenizer.texts_to_sequences(X_train_text.summary)\n",
    "\n",
    "X_test_summary_tokens = summary_tokenizer.texts_to_sequences(X_test_text.summary)\n",
    "test_summary_tokens = summary_tokenizer.texts_to_sequences(test_text.summary)\n",
    "\n",
    "# description\n",
    "description_tokenizer = Tokenizer(oov_token=1, filters='!\"#$%&()*+,-.:;<=>?@[\\\\]^`{|}~\\t\\n', lower=False)\n",
    "description_tokenizer.fit_on_texts(X_train_text.description)\n",
    "X_train_description_tokens = description_tokenizer.texts_to_sequences(X_train_text.description)\n",
    "\n",
    "X_test_description_tokens = description_tokenizer.texts_to_sequences(X_test_text.description)\n",
    "test_description_tokens = description_tokenizer.texts_to_sequences(test_text.description)\n",
    "\n",
    "# amenities\n",
    "amenities_tokenizer = Tokenizer(oov_token=1, filters='!\"#$%&()*+,-.:;<=>?@[\\\\]^`{|}~\\t\\n', lower=False)\n",
    "amenities_tokenizer.fit_on_texts(X_train_text.amenities)\n",
    "X_train_amenities_tokens = amenities_tokenizer.texts_to_sequences(X_train_text.amenities)\n",
    "\n",
    "X_test_amenities_tokens = amenities_tokenizer.texts_to_sequences(X_test_text.amenities)\n",
    "test_amenities_tokens = amenities_tokenizer.texts_to_sequences(test_text.amenities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c46e37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_X_train_name = pad_sequences(X_train_name_tokens, name_pad_len)\n",
    "padded_X_test_name = pad_sequences(X_test_name_tokens, name_pad_len)\n",
    "padded_test_name = pad_sequences(test_name_tokens, name_pad_len)\n",
    "\n",
    "padded_X_train_summary = pad_sequences(X_train_summary_tokens, summary_pad_len)\n",
    "padded_X_test_summary = pad_sequences(X_test_summary_tokens, summary_pad_len)\n",
    "padded_test_summary = pad_sequences(test_summary_tokens, summary_pad_len)\n",
    "\n",
    "padded_X_train_description = pad_sequences(X_train_description_tokens, description_pad_len)\n",
    "padded_X_test_description = pad_sequences(X_test_description_tokens, description_pad_len)\n",
    "padded_test_description = pad_sequences(test_description_tokens, description_pad_len)\n",
    "\n",
    "padded_X_train_amenities = pad_sequences(X_train_amenities_tokens, amenities_pad_len)\n",
    "padded_X_test_amenities = pad_sequences(X_test_amenities_tokens, amenities_pad_len)\n",
    "padded_test_amenities = pad_sequences(test_amenities_tokens, amenities_pad_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee15902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_vocab_size = len(name_tokenizer.word_index) + 1\n",
    "summary_vocab_size = len(summary_tokenizer.word_index) + 1\n",
    "description_vocab_size = len(description_tokenizer.word_index) + 1\n",
    "amenities_vocab_size = len(amenities_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934bf377",
   "metadata": {},
   "source": [
    "## 3.5 Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc006aa5",
   "metadata": {},
   "source": [
    "After padding, each tokens are transformed into word embeddings (word vectors). Word Embedding is preferable over Bag-of-words because the distance between word vectors contain the relationships between words. For this assignment, a pretrained GloVe vectors is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3329d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = 'glove.6B.50d.txt'\n",
    "\n",
    "glove_index = {}\n",
    "start = time.time()\n",
    "i = 0\n",
    "with open(glove, 'r', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        glove_index[word] = coefs\n",
    "        i += 1\n",
    "        #if i % 50000 == 0:\n",
    "            #print('Read {} lines of embeddings in {} sec.'.format(i, time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac11399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(tokenizer, pretrain, vocab_size, verbose=0):\n",
    "    '''\n",
    "        Helper function to construct an embedding matrix for \n",
    "        the focal corpus based on some pre-trained embeddings.\n",
    "    '''\n",
    "    \n",
    "    dim = 0\n",
    "    if isinstance(pretrain, KeyedVectors) or isinstance(pretrain, Word2VecKeyedVectors):\n",
    "        dim = pretrain.vector_size        \n",
    "    elif isinstance(pretrain, dict):\n",
    "        dim = next(iter(pretrain.values())).shape[0]\n",
    "    else:\n",
    "        raise Exception('{} is not supported'.format(type(pretrain)))\n",
    "    \n",
    "    \n",
    "    emb_mat = np.zeros((vocab_size, dim))\n",
    "\n",
    "    oov_words = []\n",
    "    v = len(tokenizer.word_index)\n",
    "    start = time.time()\n",
    "    print('Start embedding process for {} words.'.format(v), flush=True)\n",
    "    \n",
    "    for word, i in tokenizer.word_index.items():  \n",
    "        try:\n",
    "            emb_mat[i] = pretrain[word]\n",
    "        except:\n",
    "            oov_words.append(word)\n",
    "        if i % 5000 == 0 and verbose>0:    \n",
    "            print('{}/{} words in {} sec'.format(i, v, (time.time()-start)), flush=True)\n",
    "            \n",
    "            \n",
    "    print('Created embedding matrix of shape {} in {} min '.format(emb_mat.shape, (time.time()-start)/60))\n",
    "    \n",
    "    print('Encountered {} out-of-vocabulary words.'.format(len(oov_words)))\n",
    "    return (emb_mat, oov_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66f19ae4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start embedding process for 4618 words.\n",
      "Created embedding matrix of shape (4619, 50) in 0.0005163669586181641 min \n",
      "Encountered 956 out-of-vocabulary words.\n",
      "Start embedding process for 14736 words.\n",
      "Created embedding matrix of shape (14737, 50) in 0.0013324777285257975 min \n",
      "Encountered 3392 out-of-vocabulary words.\n",
      "Start embedding process for 25626 words.\n",
      "Created embedding matrix of shape (25627, 50) in 0.0015990813573201498 min \n",
      "Encountered 8312 out-of-vocabulary words.\n",
      "Start embedding process for 273 words.\n",
      "Created embedding matrix of shape (274, 50) in 0.00011659065882364908 min \n",
      "Encountered 1 out-of-vocabulary words.\n"
     ]
    }
   ],
   "source": [
    "name_glove_weights, _ = get_embedding_matrix(name_tokenizer, glove_index, name_vocab_size)\n",
    "summary_glove_weights, _ = get_embedding_matrix(summary_tokenizer, glove_index, summary_vocab_size)\n",
    "description_glove_weights, _ = get_embedding_matrix(description_tokenizer, glove_index, description_vocab_size)\n",
    "amenities_glove_weights, _ = get_embedding_matrix(amenities_tokenizer, glove_index, amenities_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f72d144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nontext_colnames = X_train.columns # save the column names before it is lose in standardiser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83894187",
   "metadata": {},
   "source": [
    "Before proceeding further, all numeric features are standardised so that the network's learning considers all input fetures equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80713834",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e11e02",
   "metadata": {},
   "source": [
    "# 4. Model Evaluation\n",
    "\n",
    "## 4.1.1 Linear Regression (LR)\n",
    "\n",
    "When it comes to prediction using numeric features, the first that usually comes to mind is linear regression. Here, linear regression will be used as the benchmark model and the involvement of text features and neural network could be observed by seeing the changes in Mean Absolute Error (MAE) and Mean Squared Error (MSE) when comparing linear regression to some neural networks model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e43b52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_X_train = X_train.copy()\n",
    "linear_X_train = pd.DataFrame(linear_X_train)\n",
    "linear_X_train.columns = nontext_colnames\n",
    "linear_X_train = sm.add_constant(linear_X_train)\n",
    "\n",
    "linear_X_test = X_test.copy()\n",
    "linear_X_test = pd.DataFrame(linear_X_test)\n",
    "linear_X_test.columns = nontext_colnames\n",
    "linear_X_test = sm.add_constant(linear_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9ae437dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.557\n",
      "Model:                            OLS   Adj. R-squared:                  0.557\n",
      "Method:                 Least Squares   F-statistic:                     3274.\n",
      "Date:                Tue, 06 Sep 2022   Prob (F-statistic):               0.00\n",
      "Time:                        12:31:08   Log-Likelihood:            -2.4052e+05\n",
      "No. Observations:               44227   AIC:                         4.811e+05\n",
      "Df Residuals:                   44209   BIC:                         4.812e+05\n",
      "Df Model:                          17                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================================\n",
      "                                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "const                          104.2550      0.265    393.806      0.000     103.736     104.774\n",
      "experiences_offered              0.6582      0.267      2.468      0.014       0.135       1.181\n",
      "host_is_superhost                0.6686      0.272      2.458      0.014       0.135       1.202\n",
      "host_total_listings_count       13.8975      0.272     51.086      0.000      13.364      14.431\n",
      "host_has_profile_pic            -0.4071      0.265     -1.536      0.125      -0.927       0.113\n",
      "host_identity_verified          -1.4606      0.290     -5.041      0.000      -2.029      -0.893\n",
      "neighbourhood                   22.8790      0.282     81.027      0.000      22.326      23.432\n",
      "property_type                    2.7778      0.279      9.953      0.000       2.231       3.325\n",
      "room_type                       19.9641      0.336     59.489      0.000      19.306      20.622\n",
      "accommodates                    17.0735      0.550     31.032      0.000      15.995      18.152\n",
      "bathrooms                        9.5401      0.309     30.883      0.000       8.935      10.146\n",
      "bedrooms                        16.8841      0.433     38.970      0.000      16.035      17.733\n",
      "beds                            -1.3339      0.454     -2.937      0.003      -2.224      -0.444\n",
      "bed_type                         0.3867      0.266      1.455      0.146      -0.134       0.907\n",
      "guests_included                  1.0610      0.310      3.426      0.001       0.454       1.668\n",
      "cancellation_policy              2.1791      0.283      7.690      0.000       1.624       2.735\n",
      "host_since_days_after_launch    -1.9939      0.290     -6.872      0.000      -2.563      -1.425\n",
      "average_sentiment                0.7271      0.270      2.696      0.007       0.198       1.256\n",
      "==============================================================================\n",
      "Omnibus:                    22304.317   Durbin-Watson:                   2.002\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           265288.256\n",
      "Skew:                           2.149   Prob(JB):                         0.00\n",
      "Kurtosis:                      14.202   Cond. No.                         4.61\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y_train, linear_X_train)\n",
    "ols = model.fit()\n",
    "print(ols.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d1d4d76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_val_prediction = ols.predict(linear_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47f5e6e",
   "metadata": {},
   "source": [
    "A function that calculates Mean Absolute Error (MAE) and Mean Squared Error (MSE) is created to determine MAE and MSE of different models for comparison and selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cdb5892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mse(prediction, true):\n",
    "    mae = np.mean(np.absolute(prediction - true))\n",
    "    mse = np.mean(np.square(prediction - true))\n",
    "    \n",
    "    return (mae, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "60dede7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_linear_mae, val_linear_mse = mae_mse(linear_val_prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f9ec90",
   "metadata": {},
   "source": [
    "## 4.1.2 LR with variable selection\n",
    "\n",
    "Upon inspection of the linear regression summary, realized that 'host_has_profile_pic' and 'bed_type' have p-value that are more than 10%, thus they are statistically insignificance based on 10% significance level. Another linear regression model is being created excluding 'host_has_profile_pic' and 'bed_type':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8c9fbd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable selection based on 5% significance level\n",
    "selected_linear_X_train = linear_X_train.drop(['host_has_profile_pic', 'bed_type'], axis = 1)\n",
    "selected_linear_X_test = linear_X_test.drop(['host_has_profile_pic', 'bed_type'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3419078b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.557\n",
      "Model:                            OLS   Adj. R-squared:                  0.557\n",
      "Method:                 Least Squares   F-statistic:                     3710.\n",
      "Date:                Tue, 06 Sep 2022   Prob (F-statistic):               0.00\n",
      "Time:                        13:00:54   Log-Likelihood:            -2.4052e+05\n",
      "No. Observations:               44227   AIC:                         4.811e+05\n",
      "Df Residuals:                   44211   BIC:                         4.812e+05\n",
      "Df Model:                          15                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================================\n",
      "                                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "const                          104.2550      0.265    393.795      0.000     103.736     104.774\n",
      "experiences_offered              0.6657      0.267      2.496      0.013       0.143       1.188\n",
      "host_is_superhost                0.6576      0.272      2.418      0.016       0.125       1.191\n",
      "host_total_listings_count       13.8971      0.272     51.085      0.000      13.364      14.430\n",
      "host_identity_verified          -1.4789      0.290     -5.106      0.000      -2.047      -0.911\n",
      "neighbourhood                   22.8794      0.282     81.027      0.000      22.326      23.433\n",
      "property_type                    2.7812      0.279      9.966      0.000       2.234       3.328\n",
      "room_type                       19.9718      0.336     59.518      0.000      19.314      20.630\n",
      "accommodates                    17.0753      0.550     31.035      0.000      15.997      18.154\n",
      "bathrooms                        9.5390      0.309     30.879      0.000       8.934      10.144\n",
      "bedrooms                        16.8984      0.433     39.008      0.000      16.049      17.748\n",
      "beds                            -1.3334      0.454     -2.936      0.003      -2.224      -0.443\n",
      "guests_included                  1.0562      0.310      3.410      0.001       0.449       1.663\n",
      "cancellation_policy              2.1733      0.283      7.671      0.000       1.618       2.729\n",
      "host_since_days_after_launch    -2.0194      0.290     -6.967      0.000      -2.587      -1.451\n",
      "average_sentiment                0.7231      0.270      2.681      0.007       0.194       1.252\n",
      "==============================================================================\n",
      "Omnibus:                    22298.182   Durbin-Watson:                   2.002\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           265047.715\n",
      "Skew:                           2.148   Prob(JB):                         0.00\n",
      "Kurtosis:                      14.197   Cond. No.                         4.61\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "selected_model = sm.OLS(y_train, selected_linear_X_train)\n",
    "selected_ols = selected_model.fit()\n",
    "print(selected_ols.summary())\n",
    "selected_linear_val_prediction = selected_ols.predict(selected_linear_X_test)\n",
    "val_selected_linear_mae, val_selected_linear_mse = mae_mse(selected_linear_val_prediction, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1e63f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: \n",
      " MAE: 35.45916029837819 \n",
      " MSE: 3175.9641491388847 \n",
      " \n",
      " LR with variable selection: \n",
      " MAE: 35.45368539839011 \n",
      " MSE:  3175.716181146826\n"
     ]
    }
   ],
   "source": [
    "print('LR: \\n MAE:', val_linear_mae, '\\n MSE:', val_linear_mse, \n",
    "      '\\n \\n LR with variable selection: \\n MAE:', val_selected_linear_mae, '\\n MSE: ', val_selected_linear_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babf98c7",
   "metadata": {},
   "source": [
    "Linear model using only statistical significant variable yields similar result compare to the one using 'host_has_profile_pic' and 'bed_type' as well, there are improvement but only very slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f23643",
   "metadata": {},
   "source": [
    "# 4.2 Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f32e7b",
   "metadata": {},
   "source": [
    "After establishing the benchmark LR model, now several neural network models could be developed and compare to our benchmark. For RNNs' text features, it is decided that 'name', 'summary', 'description' and 'amenities' are to be included for full model while for some, only the 'summary' text feature is included for faster learning. As for activation function 'relu' is used because the target price is never negative.\n",
    "\n",
    "Some of the models that have been done are:\n",
    "1. Feedforward Neural Network (FNN)\n",
    "2. Gated Reccurent Unit (GRU) with only summary\n",
    "3. LSTM with full text features\n",
    "4. Long Short-Term Memory (LSTM) with only summary\n",
    "5. LSTM with full text features\n",
    "6. Bidirectional LSTM (BiLSTM)\n",
    "\n",
    "Note that not all Recurrent Neural Netowrks (RNNs) code are included in this jupyter notebook as they have similar structure and will only make the notebook more tedious to read. However, their MAE and MSE will be included during the model comparisons. Another notebook will be uploaded to moodle containing codes for those excluded session and simply copy and paste those part into this notebook if you wish to execute those parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3463eb2",
   "metadata": {},
   "source": [
    "# 4.2.1 FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d2628ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 17)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               4608      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,385\n",
      "Trainable params: 48,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(X_train.shape[1],))\n",
    "layer1 = layers.Dense(256,  activation = 'relu',\n",
    "                      kernel_initializer=keras.initializers.he_normal(seed = 235), bias_initializer='zeros')(inputs)\n",
    "\n",
    "layer2 = layers.Dense(128, activation = 'relu', \n",
    "                      kernel_initializer=keras.initializers.he_normal(seed = 235), bias_initializer='zeros')(layer1)\n",
    "\n",
    "layer3 = layers.Dense(64, activation = 'relu', \n",
    "                      kernel_initializer=keras.initializers.he_normal(seed = 235), bias_initializer='zeros')(layer2)\n",
    "\n",
    "layer4 = layers.Dense(32, activation = 'relu', \n",
    "                      kernel_initializer=keras.initializers.he_normal(seed = 235), bias_initializer='zeros')(layer3)\n",
    "\n",
    "layer5 = layers.Dense(16, activation = 'relu', \n",
    "                      kernel_initializer=keras.initializers.he_normal(seed = 235), bias_initializer='zeros')(layer4)\n",
    "\n",
    "\n",
    "predictions = layers.Dense(1, activation = 'relu')(layer5)\n",
    "\n",
    "fnn = keras.Model(inputs = inputs, outputs = predictions)\n",
    "fnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b3aa29dd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "260/260 [==============================] - 2s 4ms/step - loss: 3455.3787 - mse: 3455.3787 - mae: 36.1573 - val_loss: 3160.9531 - val_mse: 3160.9531 - val_mae: 36.6797\n",
      "Epoch 2/25\n",
      "260/260 [==============================] - 1s 3ms/step - loss: 2987.0774 - mse: 2987.0774 - mae: 33.7168 - val_loss: 2856.0120 - val_mse: 2856.0120 - val_mae: 31.6170\n",
      "Epoch 3/25\n",
      "260/260 [==============================] - 1s 3ms/step - loss: 2923.4954 - mse: 2923.4954 - mae: 33.2649 - val_loss: 2794.3704 - val_mse: 2794.3704 - val_mae: 33.4036\n",
      "Epoch 4/25\n",
      "260/260 [==============================] - 1s 3ms/step - loss: 2857.3025 - mse: 2857.3025 - mae: 32.9817 - val_loss: 2774.2446 - val_mse: 2774.2446 - val_mae: 31.4385\n",
      "Epoch 5/25\n",
      "260/260 [==============================] - 1s 3ms/step - loss: 2839.9880 - mse: 2839.9880 - mae: 32.8668 - val_loss: 2749.5227 - val_mse: 2749.5227 - val_mae: 32.7869\n",
      "Epoch 6/25\n",
      "260/260 [==============================] - 1s 3ms/step - loss: 2828.6453 - mse: 2828.6453 - mae: 32.7958 - val_loss: 3283.8762 - val_mse: 3283.8762 - val_mae: 39.4992\n",
      "Epoch 7/25\n",
      "260/260 [==============================] - 1s 3ms/step - loss: 2867.8408 - mse: 2867.8408 - mae: 33.0783 - val_loss: 2759.9365 - val_mse: 2759.9365 - val_mae: 31.6137\n",
      "Epoch 8/25\n",
      "259/260 [============================>.] - ETA: 0s - loss: 2736.3186 - mse: 2736.3186 - mae: 32.3332Restoring model weights from the end of the best epoch: 5.\n",
      "260/260 [==============================] - 1s 3ms/step - loss: 2735.2756 - mse: 2735.2756 - mae: 32.3271 - val_loss: 2782.0344 - val_mse: 2782.0344 - val_mae: 33.3315\n",
      "Epoch 8: early stopping\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.01) \n",
    "\n",
    "# fnn.compile(optimizer=opt, loss='mean_squared_error', metrics=['mse', 'mae'])\n",
    "fnn.compile(optimizer=opt, loss='mean_squared_error', metrics=['mse', 'mae'])\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 25\n",
    "\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=0.01, restore_best_weights=True)]\n",
    "\n",
    "story = fnn.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split = 0.25,\n",
    "               callbacks=callbacks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4b1cc1ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 3s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11057.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>107.762131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>68.017258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.356299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51.011524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>94.037758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>142.047211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>600.798340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price\n",
       "count  11057.000000\n",
       "mean     107.762131\n",
       "std       68.017258\n",
       "min       15.356299\n",
       "25%       51.011524\n",
       "50%       94.037758\n",
       "75%      142.047211\n",
       "max      600.798340"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnn_val_prediction = fnn.predict(X_test)\n",
    "listing_id = pd.DataFrame(X_test_listing_id, columns = [\"listing_id\"])\n",
    "fnn_val_prediction = pd.DataFrame(fnn_val_prediction, columns = [\"price\"])\n",
    "fnn_val_prediction.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e55cc94",
   "metadata": {},
   "source": [
    "The predictions from FNN seems to be in a plausible range and no resulting null prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee41fb12",
   "metadata": {},
   "source": [
    " # 4.2.2 GRU\n",
    " \n",
    "As for RNN, GRU and Bidirectional LSTM are shown here because based on evaluation using X_test, these two performed better over all other models considered here. RNN is suitable for the task here because we have full text data for both train and test data and RNN will be able to recognise the patterns across the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e288def",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 63)]         0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 407)]        0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 735)]        0           []                               \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 402)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 63, 50)       230950      ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 407, 50)      736850      ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 735, 50)      1281350     ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 402, 50)      13700       ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " gru_3 (GRU)                    (None, 25)           5775        ['embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " gru_4 (GRU)                    (None, 100)          45600       ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " gru_5 (GRU)                    (None, 100)          45600       ['embedding_5[0][0]']            \n",
      "                                                                                                  \n",
      " gru_6 (GRU)                    (None, 100)          45600       ['embedding_6[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            26          ['gru_3[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            101         ['gru_4[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            101         ['gru_5[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 1)            101         ['gru_6[0][0]']                  \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 17)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 21)           0           ['dense_3[0][0]',                \n",
      "                                                                  'dense_4[0][0]',                \n",
      "                                                                  'dense_5[0][0]',                \n",
      "                                                                  'dense_6[0][0]',                \n",
      "                                                                  'input_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 256)          5632        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          32896       ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 64)           8256        ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1)            65          ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,452,603\n",
      "Trainable params: 2,452,603\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_name = Input(shape=(name_pad_len, ))\n",
    "name_embeddings = Embedding(name_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(name_glove_weights),\n",
    "                     input_length = name_pad_len, trainable = True)(input_name) \n",
    "GRU_name = GRU(25)(name_embeddings)\n",
    "dense_name = Dense(1, activation =\"linear\")(GRU_name)\n",
    "\n",
    "\n",
    "input_summary = Input(shape = (summary_pad_len, ))\n",
    "summary_embeddings = Embedding(summary_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(summary_glove_weights),\n",
    "                     input_length = summary_pad_len, trainable = True)(input_summary)\n",
    "GRU_summary = GRU(100)(summary_embeddings)\n",
    "dense_summary = Dense(1, activation =\"linear\")(GRU_summary)\n",
    "\n",
    "\n",
    "input_description = Input(shape = (description_pad_len, ))\n",
    "description_embeddings = Embedding(description_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(description_glove_weights),\n",
    "                     input_length = description_pad_len, trainable = True)(input_description)\n",
    "GRU_description = GRU(100)(description_embeddings)\n",
    "dense_description = Dense(1, activation=\"linear\")(GRU_description)\n",
    "\n",
    "\n",
    "input_amenities = Input(shape = (amenities_pad_len, ))\n",
    "amenities_embeddings = Embedding(amenities_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(amenities_glove_weights),\n",
    "                     input_length = description_pad_len, trainable = True)(input_amenities)\n",
    "GRU_amenities = GRU(100)(amenities_embeddings)\n",
    "dense_amenities = Dense(1, activation=\"linear\")(GRU_amenities)\n",
    "\n",
    "\n",
    "input_nontext = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "\n",
    "# Concatenate\n",
    "concat = concatenate([dense_name, dense_summary, dense_description, dense_amenities, input_nontext])\n",
    "dense_full1 = Dense(256, activation = \"relu\")(concat)\n",
    "dense_full2 = Dense(128, activation=\"relu\")(dense_full1)\n",
    "dense_full3 = Dense(64, activation=\"relu\")(dense_full2)\n",
    "output_layer = Dense(1, activation = \"linear\")(dense_full3)\n",
    "\n",
    "model = Model(inputs=[input_name, input_summary, input_description, input_amenities, input_nontext], outputs = output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4edd4bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "260/260 [==============================] - 1947s 7s/step - loss: 3406.3284 - mse: 3406.3284 - mae: 35.9482 - val_loss: 2908.2617 - val_mse: 2908.2617 - val_mae: 36.1614\n",
      "Epoch 2/25\n",
      "260/260 [==============================] - 2083s 8s/step - loss: 2488.1711 - mse: 2488.1711 - mae: 30.9196 - val_loss: 2817.3027 - val_mse: 2817.3027 - val_mae: 35.2737\n",
      "Epoch 3/25\n",
      "260/260 [==============================] - 2115s 8s/step - loss: 2008.9611 - mse: 2008.9611 - mae: 27.6247 - val_loss: 2556.6384 - val_mse: 2556.6384 - val_mae: 30.9675\n",
      "Epoch 4/25\n",
      "260/260 [==============================] - 2137s 8s/step - loss: 1655.8984 - mse: 1655.8984 - mae: 25.2366 - val_loss: 2894.1531 - val_mse: 2894.1531 - val_mae: 31.7742\n",
      "Epoch 5/25\n",
      "260/260 [==============================] - 2155s 8s/step - loss: 1430.2676 - mse: 1430.2676 - mae: 23.6333 - val_loss: 2854.5586 - val_mse: 2854.5586 - val_mae: 31.3858\n",
      "Epoch 6/25\n",
      "260/260 [==============================] - ETA: 0s - loss: 1251.6787 - mse: 1251.6787 - mae: 22.3736Restoring model weights from the end of the best epoch: 3.\n",
      "260/260 [==============================] - 2143s 8s/step - loss: 1251.6787 - mse: 1251.6787 - mae: 22.3736 - val_loss: 2833.4216 - val_mse: 2833.4216 - val_mae: 31.0926\n",
      "Epoch 6: early stopping\n",
      "12580.574478626251\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.01) \n",
    "\n",
    "model.compile(optimizer = opt, loss='mean_squared_error', metrics=['mse', 'mae'])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 25\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=0.01, restore_best_weights=True)]\n",
    "\n",
    "story = model.fit([padded_X_train_name, padded_X_train_summary, padded_X_train_description, padded_X_train_amenities, X_train], y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs,\n",
    "                    verbose = 1,\n",
    "                    validation_split = 0.25,\n",
    "                  callbacks = callbacks) \n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f58948e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 92s 261ms/step\n"
     ]
    }
   ],
   "source": [
    "gru_val_prediction = model.predict([padded_X_test_name, padded_X_test_summary, padded_X_test_description, padded_X_test_amenities, X_test])\n",
    "gru_val_prediction = pd.DataFrame(gru_val_prediction, columns = [\"price\"])\n",
    "gru_val_result = pd.concat([X_test_listing_id, gru_val_prediction], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917c14b",
   "metadata": {},
   "source": [
    "# 4.2.3 Bidirectional LSTM (BiLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ced4b90d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 63)]         0           []                               \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 407)]        0           []                               \n",
      "                                                                                                  \n",
      " input_15 (InputLayer)          [(None, 735)]        0           []                               \n",
      "                                                                                                  \n",
      " input_16 (InputLayer)          [(None, 402)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 63, 50)       230950      ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 407, 50)      736850      ['input_14[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, 735, 50)      1281350     ['input_15[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)        (None, 402, 50)      13700       ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " bidirectional_4 (Bidirectional  (None, 50)          15200       ['embedding_5[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_5 (Bidirectional  (None, 200)         120800      ['embedding_6[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_6 (Bidirectional  (None, 200)         120800      ['embedding_7[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_7 (Bidirectional  (None, 200)         120800      ['embedding_8[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 1)            51          ['bidirectional_4[0][0]']        \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 1)            201         ['bidirectional_5[0][0]']        \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 1)            201         ['bidirectional_6[0][0]']        \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 1)            201         ['bidirectional_7[0][0]']        \n",
      "                                                                                                  \n",
      " input_17 (InputLayer)          [(None, 17)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 21)           0           ['dense_25[0][0]',               \n",
      "                                                                  'dense_26[0][0]',               \n",
      "                                                                  'dense_27[0][0]',               \n",
      "                                                                  'dense_28[0][0]',               \n",
      "                                                                  'input_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 128)          2816        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 64)           8256        ['dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 1)            65          ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,652,241\n",
      "Trainable params: 2,652,241\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_name = Input(shape=(name_pad_len, ))\n",
    "name_embeddings = Embedding(name_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(name_glove_weights),\n",
    "                     input_length = name_pad_len, trainable = True)(input_name)   # try trainable False?\n",
    "LSTM_name1 = Bidirectional(LSTM(25, return_sequences = False), merge_mode = 'concat')(name_embeddings)\n",
    "dense_name = Dense(1, activation =\"linear\")(LSTM_name1)\n",
    "\n",
    "\n",
    "input_summary = Input(shape = (summary_pad_len, ))\n",
    "summary_embeddings = Embedding(summary_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(summary_glove_weights),\n",
    "                     input_length = summary_pad_len, trainable = True)(input_summary)\n",
    "LSTM_summary1 = Bidirectional(LSTM(100, return_sequences = False), merge_mode = 'concat')(summary_embeddings)\n",
    "dense_summary = Dense(1, activation =\"linear\")(LSTM_summary1)\n",
    "\n",
    "\n",
    "input_description = Input(shape = (description_pad_len, ))\n",
    "description_embeddings = Embedding(description_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(description_glove_weights),\n",
    "                     input_length = description_pad_len, trainable = True)(input_description)\n",
    "LSTM_description1 = Bidirectional(LSTM(100, return_sequences = False), merge_mode = 'concat')(description_embeddings)\n",
    "dense_description = Dense(1, activation=\"linear\")(LSTM_description1)\n",
    "\n",
    "\n",
    "input_amenities = Input(shape = (amenities_pad_len, ))\n",
    "amenities_embeddings = Embedding(amenities_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(amenities_glove_weights),\n",
    "                     input_length = description_pad_len, trainable = True)(input_amenities)\n",
    "LSTM_amenities1 = Bidirectional(LSTM(100, return_sequences = False), merge_mode = 'concat')(amenities_embeddings)\n",
    "dense_amenities = Dense(1, activation=\"linear\")(LSTM_amenities1)\n",
    "\n",
    "\n",
    "input_nontext = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "\n",
    "# Concatenate\n",
    "concat = concatenate([dense_name, dense_summary, dense_description, dense_amenities, input_nontext])\n",
    "# dense_full1 = Dense(256, activation = \"relu\")(concat)\n",
    "dense_full2 = Dense(128, activation=\"relu\")(concat) # (dense_full1)\n",
    "dense_full3 = Dense(64, activation=\"relu\")(dense_full2)\n",
    "output_layer = Dense(1, activation = \"linear\")(dense_full3)\n",
    "\n",
    "model = Model(inputs=[input_name, input_summary, input_description, input_amenities, input_nontext], outputs = output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b711b4d6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "260/260 [==============================] - 9118s 35s/step - loss: 4628.7354 - mse: 4628.7354 - mae: 43.3041 - val_loss: 2998.5730 - val_mse: 2998.5730 - val_mae: 33.9816\n",
      "Epoch 2/25\n",
      "260/260 [==============================] - 10172s 39s/step - loss: 2911.0464 - mse: 2911.0464 - mae: 33.7629 - val_loss: 2799.9912 - val_mse: 2799.9912 - val_mae: 32.5115\n",
      "Epoch 3/25\n",
      "260/260 [==============================] - 10431s 40s/step - loss: 2494.3552 - mse: 2494.3552 - mae: 31.1039 - val_loss: 2665.5762 - val_mse: 2665.5762 - val_mae: 31.5786\n",
      "Epoch 4/25\n",
      "260/260 [==============================] - 10373s 40s/step - loss: 2125.6667 - mse: 2125.6667 - mae: 28.5542 - val_loss: 2782.5066 - val_mse: 2782.5066 - val_mae: 33.6522\n",
      "Epoch 5/25\n",
      "260/260 [==============================] - 10455s 40s/step - loss: 1848.5161 - mse: 1848.5161 - mae: 26.7494 - val_loss: 2854.8228 - val_mse: 2854.8228 - val_mae: 31.5665\n",
      "Epoch 6/25\n",
      "260/260 [==============================] - ETA: 0s - loss: 1687.5289 - mse: 1687.5289 - mae: 25.6955 Restoring model weights from the end of the best epoch: 3.\n",
      "260/260 [==============================] - 10616s 41s/step - loss: 1687.5289 - mse: 1687.5289 - mae: 25.6955 - val_loss: 3112.2971 - val_mse: 3112.2971 - val_mae: 33.9393\n",
      "Epoch 6: early stopping\n",
      "61164.87641596794\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.01) \n",
    "\n",
    "model.compile(optimizer = opt, loss='mean_squared_error', metrics=['mse', 'mae'])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 25\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=0.01, restore_best_weights=True)]\n",
    "\n",
    "story = model.fit([padded_X_train_name, padded_X_train_summary, padded_X_train_description, padded_X_train_amenities, X_train], y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs,\n",
    "                    verbose = 1,\n",
    "                    validation_split = 0.25,\n",
    "                  callbacks = callbacks) \n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "37e05822",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 638s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11057.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>103.877930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>65.880722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.682997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49.894409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>88.582153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>137.548981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>576.065674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price\n",
       "count  11057.000000\n",
       "mean     103.877930\n",
       "std       65.880722\n",
       "min       17.682997\n",
       "25%       49.894409\n",
       "50%       88.582153\n",
       "75%      137.548981\n",
       "max      576.065674"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm_val_prediction = model.predict([padded_X_test_name, padded_X_test_summary, padded_X_test_description, padded_X_test_amenities, X_test])\n",
    "listing_id = pd.DataFrame(X_test_listing_id, columns = [\"listing_id\"])\n",
    "bilstm_val_prediction = pd.DataFrame(bilstm_val_prediction, columns = [\"price\"])\n",
    "bilstm_val_prediction.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb054e85",
   "metadata": {},
   "source": [
    "# 5. Model Comparison and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "276624be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRU</td>\n",
       "      <td>31.547228</td>\n",
       "      <td>2653.220379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>32.682837</td>\n",
       "      <td>2821.475437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRU with summary only</td>\n",
       "      <td>32.750107</td>\n",
       "      <td>2832.827207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM with summary only</td>\n",
       "      <td>32.888887</td>\n",
       "      <td>2916.223470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>33.006442</td>\n",
       "      <td>2807.883639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FNN</td>\n",
       "      <td>33.323926</td>\n",
       "      <td>2866.239236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR with variable selection</td>\n",
       "      <td>35.453685</td>\n",
       "      <td>3175.716181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR</td>\n",
       "      <td>35.459160</td>\n",
       "      <td>3175.964149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model        MAE          MSE\n",
       "0                         GRU  31.547228  2653.220379\n",
       "1                      BiLSTM  32.682837  2821.475437\n",
       "2       GRU with summary only  32.750107  2832.827207\n",
       "3      LSTM with summary only  32.888887  2916.223470\n",
       "4                        LSTM  33.006442  2807.883639\n",
       "5                         FNN  33.323926  2866.239236\n",
       "6  LR with variable selection  35.453685  3175.716181\n",
       "7                          LR  35.459160  3175.964149"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_comparison = pd.read_csv(\"comparison.csv\", sep = \",\", encoding = \"utf-8\")\n",
    "models_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655f94d6",
   "metadata": {},
   "source": [
    "Comparing all considered models, most results are expected while some are not:\n",
    "1. Linear Regression performed worst as it only include non-text features with variable selection improved it slightly.\n",
    "2. FNN with only non-text features performed only better than linear regressions.\n",
    "3. BiLSTM performed better than LSTM as it is more complex.\n",
    "4. GRU with summary was included after seeing the unexpected result of LSTM with summary only perform better than full LSTM but it performs worst than full GRU which is to be expected.\n",
    "5. GRU performs better than LSTM and BiLSTM is not expected since generally GRU uses less memory and is faster than LSTM but LSTM is more accurate when using datasets with longer sequences.\n",
    "\n",
    "It is also understandable that the results of neural networks is affected by the randomness during training and GRU might not actually be the best one overall (since the mae and mse is not a lot lower than the others) but according to the model valuation using X_test and these training, GRU performed the best out of all considered model and thus are selected to be applied to Test Set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5be13c8",
   "metadata": {},
   "source": [
    "# 6. GRU application to Test Set\n",
    "\n",
    "After deciding for GRU, all train data should be combined together for model training so that we could use all available data more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97718004",
   "metadata": {},
   "source": [
    "Firstly, check if mode of X (X_test and X_train combined before the splitting) and X_train are the same for 'host_since', 'host_total_listings_count','host_is_superhost','host_has_profile_pic', 'host_identity_verified', 'bathrooms', 'bedrooms', 'beds'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72d8b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 934)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0df1b952",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host_since :  True\n",
      "host_total_listings_count :  True\n",
      "host_is_superhost :  True\n",
      "host_has_profile_pic :  True\n",
      "host_identity_verified :  True\n",
      "bathrooms :  True\n",
      "bedrooms :  True\n",
      "beds :  True\n"
     ]
    }
   ],
   "source": [
    "for col in ['host_since', 'host_total_listings_count','host_is_superhost','host_has_profile_pic', \n",
    "            'host_identity_verified', 'bathrooms', 'bedrooms', 'beds']:\n",
    "    print(col, ': ', mode(X[col]) == mode(X_train[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e4219e",
   "metadata": {},
   "source": [
    "The editted non-text data can directly be combined since those replaced missing values will still be replaced by the same mode values after combining X_train and X_test again. y_train and y_test can be concatenated together directly since no changes are made to them. After that, all similar steps are performed again for the GRU while using train instead of X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec1d945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"prepared_X_train.csv\", sep=\",\", encoding = \"utf-8\")\n",
    "X_test = pd.read_csv(\"prepared_X_test.csv\", sep=\",\", encoding = \"utf-8\")\n",
    "test = pd.read_csv(\"prepared_test.csv\", sep=\",\", encoding = \"utf-8\")\n",
    "# Intermediate result that couldn't be uploaded to moodle.\n",
    "# These are the data after the data_preparation function in section 3.3\n",
    "# Please let me know if needed and I would be happy to email them\n",
    "\n",
    "train = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "\n",
    "train_text = train[['name', 'summary', 'description', 'amenities']]\n",
    "test_text = test[['name', 'summary', 'description', 'amenities']]\n",
    "\n",
    "for df in [train, test]:\n",
    "    df = df.drop(['name', 'summary', 'description', 'amenities'], axis = 1, inplace = True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a20c9974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name       CDF\n",
      "0   21.6  0.217567\n",
      "1   42.2  0.884976\n",
      "2   62.8  0.998788\n",
      "3   83.4  0.999692\n",
      "4  104.0  0.999910\n",
      "5  124.6  0.999946\n",
      "6  145.2  0.999946\n",
      "7  165.8  0.999964\n",
      "8  186.4  0.999982\n",
      "9  207.0  1.000000 \n",
      "\n",
      "   summary       CDF\n",
      "0     83.8  0.118805\n",
      "1    164.6  0.282306\n",
      "2    245.4  0.520567\n",
      "3    326.2  0.780714\n",
      "4    407.0  0.986361\n",
      "5    487.8  0.991191\n",
      "6    568.6  0.992258\n",
      "7    649.4  0.994537\n",
      "8    730.2  0.998390\n",
      "9    811.0  1.000000 \n",
      "\n",
      "   description       CDF\n",
      "0         93.0  0.062930\n",
      "1        185.0  0.124882\n",
      "2        277.0  0.185479\n",
      "3        369.0  0.266261\n",
      "4        461.0  0.314974\n",
      "5        553.0  0.365042\n",
      "6        645.0  0.548748\n",
      "7        737.0  0.934104\n",
      "8        829.0  0.997920\n",
      "9        921.0  1.000000 \n",
      "\n",
      "   amenities       CDF\n",
      "0      139.7  0.215325\n",
      "1      270.4  0.655832\n",
      "2      401.1  0.904819\n",
      "3      531.8  0.984064\n",
      "4      662.5  0.996473\n",
      "5      793.2  0.998589\n",
      "6      923.9  0.999367\n",
      "7     1054.6  0.999765\n",
      "8     1185.3  0.999910\n",
      "9     1316.0  1.000000 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'name'}>,\n",
       "        <AxesSubplot:title={'center':'summary'}>],\n",
       "       [<AxesSubplot:title={'center':'description'}>,\n",
       "        <AxesSubplot:title={'center':'amenities'}>]], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcXklEQVR4nO3df7RdZX3n8fcnIaQSokAiIQQkFCkVK1NJBJxSvUuLkNSY/hANSwVZncnCkdVxRh1onKnMSFG6ZqyDWCJVDCg/tGNtY0UBO9ziDIIkDiAgVwJGE3IhJhS4NyBp4Dt/7OeWzcm59557cs85ez/n81prr7vP/nWe/ezv+d69n/1LEYGZmdXfjF4XwMzMpocTuplZJpzQzcwy4YRuZpYJJ3Qzs0w4oZuZZcIJ3cwsE07oZmaZcEI3s2xJ2q/XZegmJ/QOkrRZ0kck3SvpKUlflfQrkg6W9PeSfiHpn1L/EaX5BiVdLOl2SaOSvilpnqRrJT0t6S5Ji0vT/7qkWyQ9IWlI0rt6ssKWJUkXSHpU0kiKr7dKWifp4tI0A5K2lj5vlvTRFPu7JH1R0gJJ307L+a6kg9O0iyWFpHMlbUm/ifMkvSHN/6Sky0vLPkbS/5a0U9KO9Ls4qOG7L5B0L7ArlePrDev0WUmf6WC19YQTeue9CzgDOBo4AXg/Rb1/CTgKeBXwLHB5w3yrgPcBi4BjgO+neQ4Bfgx8HEDSHOAW4DrgUOAs4C8lvbaD62R9QtJxwPnAGyJiLnA6sLnF2f8QOA34NWAF8G1gDTCf4jfwxw3TnwwcC7wb+AzwMeB3gNcC75L05rFiAZ8EDgdeAxwJXNSwrLOA3wUOAr4CnDGW9NNe+7uBL7e4HrXhhN55l0XEtoh4Avgm8JsRsTMivh4Rz0TECPBnwJsb5vtSRDwcEU9R/BAejojvRsQe4K+B16fp3g5sjogvRcSeiPgh8HXgnV1ZO8vd88Bs4HhJsyJic0Q83OK8n42IxyPiUeB7wJ0R8f8i4jngG7wYw2M+ERG/jIibgV3A9RGxvTT/6wEiYlNE3BIRz0XEL4BPs/fv57KI2BIRz0bEMHAbcGYadwawIyI2TqkmasAJvfMeK/U/Axwo6QBJn5f0M0lPUwTbQZJmlqZ9vNT/bJPPB6b+o4CT02Hpk5KeBN4DHDbdK2L9JyI2AR+i2APeLukGSYe3OHurMTyl6SUdmsrxaPr9fIVir79sS8Pnq4H3pv73kuHeOTih98qHgeOAkyPi5cCb0nC1sawtwD9GxEGl7sCI+MB0Fdb6W0RcFxGnUuw8BHApxR70AaXJurkD8clUjhPS7+e97P3baXyM7N8CJ0j6DYqj2ms7XchecELvjbkUexxPSjqE1B7epr8Hfk3S+yTNSt0bJL1mWkpqfU3ScZLeImk28EuKuH0euBtYLukQSYdR7MV3y1xglOL3swj46GQzRMQvgf9Fca7pBxHx884WsTec0HvjM8DLgB3AHcB32l1QaoN/G8VJ1G0UTTyXUrR7mu2r2cCnKGL1MYoT72somizuoThBejPw1S6W6b8CJwJPAd8C/qbF+a4GXkemzS0A8gsuzKwfSHoV8CBwWEQ83evydIL30M0se5JmAP8RuCHXZA7QV3dRmVn/SfdqPA78jOKSxWy5ycXMLBNucjEzy0TPmlzmz58fixcv3mv4rl27mDNnTvcLVBH9vv4wtTrYuHHjjoh4ZYeLNC3Gi3mox3avehmrXj6YnjJOGPMR0ZNuyZIl0cytt97adHi/6Pf1j5haHQAbokcxPNVuvJif6jr3StXLWPXyRUxPGSeK+UmbXCRdJWm7pPvGGS9Jl0nalJ6MduI+/fsxqwDHvdVRK23o65j4zPAyiiekHQusBq7Y92KZ9dw6HPdWM5Mm9Ii4DXhigklWAteko4E7KB4ytXC6CmjWC457q6PpOCm6iJc+2WxrGjbcOKGk1RR7MyxYsIDBwcG9FjY6Otp0eCesWbOGnTt3duW7WvXCCy8wY0Z/X3zUWAfz5s3jkksu6WGJmmop7luJeehu3Ler6mWcavl68ftv9ffdbsxPR0Jv9oTAphe3R8SVwJUAS5cujYGBgb2mGRwcpNnwTti9ezdDQ0Nd+a5WdXP9q6qxDpYuXVrFOmkp7luJeajHdp9qGVesWMHw8F77dR0zMjLC3LlzW55+4cKF3H777R0s0d5arcN2Y346EvpWijeGjDmC4iFRZjlz3E9ieHiYDRs2dO376vBPsdOm49h+PXB2Out/CvBUFG8IMcuZ494qZ9I9dEnXAwPA/PQS2I8DswAiYi1wI7Ac2ETxRp5zO1VYs25x3FsdTZrQI+KsScYH8MFpK5FZBTjurY76+3IKM7OMOKGbmWXCCd3MLBNO6GZmmcjmjUXt3MSwcKHv1DazfGST0Lt9E4OZWdW4ycXMLBNO6GZmmXBCNzPLhBO6mVkmnNDNzDLhhG5mlgkndDOzTDihm5llIpsbi8ysc1asWMFPfvKTKb/izbrLCd3MJjU8PMznP//5vn/FW9W5ycXMLBNO6GZmmXBCNzPLhBO6mVkmnNDNzDLhhG5mlgkndDOzTDihm5llwgndzCwTTuhmZplwQjczy4QTuplZJpzQzcwy4YRuZpYJJ3Qzs0w4oZuZZcIJ3cwsE07oZmaZcEI3M8uEE7qZWSZaSuiSzpA0JGmTpAubjB+Q9JSku1P3p9NfVLPuccxbHe032QSSZgKfA04DtgJ3SVofEQ80TPq9iHh7B8po1lW5x/yKFSsYHh6e0jwLFy7sUGlsOk2a0IGTgE0R8QiApBuAlUBjcJvlIuuYHx4eZsOGDVOeb3BwcPoLY9OqlYS+CNhS+rwVOLnJdG+UdA+wDfhIRNzfOIGk1cBqgAULFjQNkNHR0bYCZ2RkJIuAa3f9c9JYBz3Ytl2Neejudm+3Pqsem1UvH7RexrZjPiIm7IAzgS+UPr8P+GzDNC8HDkz9y4GHJlvukiVLoplbb7216fDJjLe8uml3/XPSWAcTbVtgQ0wSa1Ptuh3zzda5k9r9rVQ9NqtevojWy9huzLdyUnQrcGTp8xEUeyTlfwpPR8Ro6r8RmCVp/hT/t5hVhWPeaqmVhH4XcKykoyXtD6wC1pcnkHSYJKX+k9Jyd053Yc26xDFvtTRpG3pE7JF0PnATMBO4KiLul3ReGr8WeCfwAUl7gGeBVenQwKx2HPNWV62cFB07pLyxYdjaUv/lwOXTWzSz3nHMWx35TlEzs0w4oZuZZcIJ3cwsE07oZmaZcEI3M8uEE7qZWSac0M3MMuGEbmaWCSd0M7NMOKGbmWXCCd3MLBNO6GZmmXBCNzPLREtPWzSz6mnnZc/gFz7nzAndrKbafdmz5ctNLmZmmXBCNzPLhBO6mVkmnNDNzDJRyZOi7Zy995l7M+t3lUzoPntvZjZ1bnIxM8uEE7qZWSac0M3MMuGEbmaWCSd0M7NMOKGbmWXCCd3MLBOVvA7drN+sWbOG3bt3T2ke30xnjZzQzSpg586dDA0N9boYVnNucjEzy4QTuplZJpzQzcwy4YRuZpYJJ3Qzs0w4oZuZZaKlhC7pDElDkjZJurDJeEm6LI2/V9KJ019Us+5xzFsdTZrQJc0EPgcsA44HzpJ0fMNky4BjU7cauGKay2nWNY55q6tW9tBPAjZFxCMRsRu4AVjZMM1K4Joo3AEcJMm3sVldOeatllq5U3QRsKX0eStwcgvTLAJe8mJQSasp9mYARiU1uzVuPrBDUgtFy9J8YEevC9Fje9XBBPFwVAe+v9sxDzBfUtW3e9Vjs+rlgymUsZ2YbyWhN1tqtDENEXElcOWEXyZtiIilLZQrS/2+/lCJOuhqzEMl1nlSVS9j1csHnS9jK00uW4EjS5+PALa1MY1ZXTjmrZZaSeh3AcdKOlrS/sAqYH3DNOuBs9OZ/1OApyJiuHFBZjXhmLdamrTJJSL2SDofuAmYCVwVEfdLOi+NXwvcCCwHNgHPAOfuQ5kmPTzNXL+vP/S4DnoQ81CP7V71Mla9fNDhMipir2Y/MzOrId8pamaWCSd0M7NMVCqhT3a7dQ4kXSVpu6T7SsMOkXSLpIfS34NL4/4k1ceQpNN7U+rpI+lISbdK+rGk+yX9+zS8b+qgrCoxP8F2uUjSo5LuTt3y0jxd3y6SNkv6USrLhjSsMrEj6bhSXd0t6WlJH+paPUZEJTqKk08PA78K7A/cAxzf63J1YD3fBJwI3Fca9ufAhan/QuDS1H98qofZwNGpfmb2eh32cf0XAiem/rnAT9J69k0dlOqiMjE/wXa5CPhIk+l7sl2AzcD8hmGVjJ20fR+juBGoK/VYpT30Vm63rr2IuA14omHwSuDq1H818Hul4TdExHMR8VOKKypO6kY5OyUihiPih6l/BPgxxR2WfVMHJZWJ+Qm2y3iqtF2qGjtvBR6OiJ9NMM20lrFKCX28W6n7wYJI1zCnv4em4VnXiaTFwOuBO+nPOqjkujVsF4Dz0xMlryo1Z/Sq7AHcLGljeqwCVDd2VgHXlz53vB6rlNBbupW6z2RbJ5IOBL4OfCginp5o0ibDsqgDKrhuTbbLFcAxwG9SPKfmf4xN2mT2bpT9tyLiRIqnXX5Q0psmmLZn9ZtuSHsH8NdpUFfqsUoJvfK3UktaJ+niDiz68bEn9aW/29PwfwOcUJqu5TqR9NsTPAiqpyTNokga10bE36TB49VB5eNiH1Rq3Zptl4h4PCKej4gXgL/ixeaArpVd0lpJ/yWVZ1v6ux34RirPP0u6Nk1bldhZBvwwIh5P5e1KPVYpobdyu3Wu1gPnpP5zgL9L/ScCp0uaLeloimdv/6DZAiSFpFePfY6I70XEcR0sc1skCfgi8OOI+HRp1Hh1sB5Y1Uod1FBlYn687aKXPhL494Gxq7O6tl0i4ryI+ISkOZKWSdoqaQ7wtlSedcCP0uRViZ2zKDW3dK0eu3XGt8Wzwsspzq4/DHys1+VpUr51wMX7uIzrKQ65/pniv/MfAfOAfwAeSn9fWZr+Y6k+hoBlEyw3gFf3uo5aWP9TU1nvBe5O3fImdXDIVOugjl1VYn6C7fJlimR5b0o+C3u1XSiuBtoE7AbuH6uvqsUOcACwE3hFaVhX6rHnAV3ljuLE0A+BEeCrFFchXJzGvT0F/ZPA7cAJpfkuAB5N8w0Bb03DZwJr0sYbATYCR6ZxAXwwBeVPS8NenfrXAWuBW9K8/wgclcbdlqbdBYwC7wYGgK2lMr0GGEzlvR94R2ncOoo39HwrLftO4Jhe17+73ncUlwGOxesDwO+n4e8H/i/wFymmHgH+dRq+haLZ45zScmYD/x34OfB4iuWXpXEDFDs3H07zDQPnluZdB1wMzAGeBV5IcT4KHE5xSeBXStOfkn6TT1JcEjhQGvf+VNYR4KfAe3pdx9O6vXpdgKp2FNcF/wz4D8As4J0Ue9UXUzSFbKd46cFMisO8zSloj0sBfXhazuKx5Ah8lOK/9HEUJ0P+FTAvjYuUrA8pBXpjQh+huI59NvA/gf9TKu9L9tApJfRU/k0U/0z2B96SlnVcadlPULTr7QdcS3EpVc+3g7vedsCZKWnOoNhR2EVxzfr7gT0UDyWbmX4XP6fYMZhN0RwyAhyYlvMZij3TQyiuc/8m8Mk0biAt67+lWF1O8cCzg9P4dby4I/UvcV0q40WkhE5xhcjOtIwZwGnp8ysp/iE8XYr7hcBre13H07q9el2AqnYpcW4jPcAsDbs9Be4VwCcaph8C3gy8miLZ/w4wq8k0K8f5vgDe0mRYOaHfUBp3IPA8L93DHy+h/zbFDQ4zSuOvBy4qLfsLpXHLgQd7vQ3cVa+jOCpdmRL6Q6Xhr0sxuKA0bCfFVR1K/wiOKY17Iy8eiQ5Q7HnvVxq/HTgl9U8loV8AfLlh/E0UO11zKPba/5C005RbV6WTolVzOPBopIhIxm4QOAr4sKQnxzqKM9WHR8Qm4EMUQbZd0g2SDk/zHUlx+DqeLROMe8n4iBil2Ks+fPzJX7IuW6I4w15el/L1ro+V+p+h+IdhfU7S2elW9bE4/w2K16hB0XQy5lkoruZoGHYgxd7xAcDG0nK+k4aP2RkRe0qf243Bo4AzG36bp1K0We+iOMo4DxiW9C1Jv97Gd1SWE/r4hoFF6ez/mFelv1uAP4uIg0rdARFxPUBEXBcRp1IEVwCXluY7ZoLvnOz603+5vCldL3wIrV3itA04UlJ5e7+Kop3frClJR1FcYnc+RdPgQRRXZ0z1hb87KJL7a0u/l1dERDsJe7LfyBaKPfTyb3NORHwKICJuiojTKJpbHqRYv2w4oY/v+xTten8saT9Jf8CL147+FXCepJNVmCPpdyXNTQ/neYuk2cAvKQL5+TTfF4BPSDo2zXeCpHlTKNNySaemS9w+AdwZEWN77Y9TXAXQzJ0Uh7z/SdIsSQPACoqTvGbjmUORQH8BIOlcij30KYkXr73+C0mHpmUtavNBVI8D8yS9YpzxXwFWSDpd0kxJvyJpQNIRkhZIeke65PE5ipOqz4+znFpyQh9HFM/W+AOKtsJ/ojhUG7vZYgPwb4HL07hNaTooTgh9imKv5DGK25DXpHGfBr4G3ExxcuaLwMumUKzrgI9TNLUsAd5TGncRcHU6zHxXk3V5B8XNDjuAvwTOjogHp/Dd1mci4gGKOxq/T5FIX0dxZUs7LqD4ndwh6WnguxQXB0y1TA9SnP95JMX64Q3jt1C08a+h+Ee0heJihBmp+zDFEesTFOe8/l2b61NJfmNRTUhaR3Ey6D/3uixmVk3eQzczy4QTuplZJtzkYmaWCe+hm5llYr9effH8+fNj8eLFTcft2rWLOXPmdLdANeL6edHGjRt3RMQrJ5+y98aL+Zy2Zy7rUuX1mCjme5bQFy9ezIYNG5qOGxwcZGBgoLsFqhHXz4skTfR6r0oZL+Zz2p65rEuV12OimJ+0yUVN3lLfMF6SLlPx1up7JZ24L4U1qwLHvdVRK23o64AzJhi/jOKh7McCqykeXGVWd+tw3FvNTJrQo/lb6stWAtdE4Q7goIa3c5jVjuPe6mg62tDHe2v1cOOEKt7SvRpgwYIFDA4ONl3g6OjouOOsOvWzZs0adu7c2fHvmTdvHpdccknHv2eKWor7VmK+KttzOpTXpVvx0QkvvPACM2b07iLAdmN+OhJ6y2+tjogrgSsBli5dGuOddKjyCYkqqEr97N69m6Ghzr+HeunSpZVY3wYtxX0rMV+V7TmRFStWMDy81z7aXkZGRpg7dy4ACxcu5Pbbb+900Tqi19uk3ZifjoReqTeXm3VJX8X98PDwuFellfU6Efa76TimWA+cnc76nwI8FRGT/ys3qzfHvVXOpHvokq6neO3TfElbKR7fOgsgItYCN1K8smwTxVtGzu1UYc26xXFvdTRpQo+IsyYZP/a2erNsOO6tjnp2p6hVR6snvBotXOir9MyqxAndWj7hZWbV5oRu1mfaOSLz0Vg9OKGb9RkfkeXLz0M3M8uEE7qZWSac0M3MMuGEbmaWCSd0M7NMOKGbmWXCCd3MLBNO6GZmmXBCNzPLhBO6mVkmnNDNzDLhhG5mlgkndDOzTDihm5llwgndzCwTTuhmZplwQjczy4QTuplZJpzQzcwy4YRuZpYJJ3Qzs0zs1+sCmFl7VqxYwfDw8JTnW7hwYQdKY1XghG5WU8PDw2zYsKHXxbAKcZOLmVkmnNDNzDLhhG5mlgkndDOzTDihm5llwgndzCwTTuhmZpnwdeiZaedmE99oYpYHJ/TM+GYTs/7VUpOLpDMkDUnaJOnCJuMHJD0l6e7U/en0F9WsexzzVkeT7qFLmgl8DjgN2ArcJWl9RDzQMOn3IuLtHSijWVc55q2uWtlDPwnYFBGPRMRu4AZgZWeLZdZTjnmrpVba0BcBW0qftwInN5nujZLuAbYBH4mI+xsnkLQaWA2wYMECBgcHm37h6OjouONs4voZGRnJru56sE5djfl2472K2zqX326v16PtbRsRE3bAmcAXSp/fB3y2YZqXAwem/uXAQ5Mtd8mSJTGeW2+9ddxxNnH9TFSvdTXROgEbYpJYm2rX7ZhvN96ruK1z+e32ej3ajflWmly2AkeWPh9BsUdS/qfwdESMpv4bgVmS5k/xf4tZVTjmrZZaSeh3AcdKOlrS/sAqYH15AkmHSVLqPyktd+d0F9asSxzzVkuTtqFHxB5J5wM3ATOBqyLifknnpfFrgXcCH5C0B3gWWJUODcxqxzFvddXSjUXpkPLGhmFrS/2XA5dPb9HMescxb3XkZ7mYmWXCCd3MLBNO6GZmmXBCNzPLhBO6mVkmnNDNzDLh56FX2HgvqxgZGWHu3LlN5/HLKsz6lxN6hY33sorBwUEGBga6XyAzqzQ3uZiZZcIJ3cwsE25y6RK/vNnMOs0JvUv88mYz6zQ3uZiZZcIJ3cwsE07oZmaZcBt6G3yC08yqyAm9DT7BaWZV5CYXM7NMOKGbmWXCTS5mFeDzMjYdnNDNKsDnZWw6uMnFzCwTfb2H3s5hLvhQ18yqqa8Tug9zzSwnbnIxM8uEE7qZWSac0M3MMuGEbmaWiWxOivrGDDPrd9kkdF+xYmb9zk0uZmaZcEI3M8uEE7qZWSYq2Ya+Zs0adu/ePaV5fILTzPpdJRP6zp07GRoa6nUxzMxqxU0uZmaZaCmhSzpD0pCkTZIubDJeki5L4++VdOL0F9WsexzzVkeTJnRJM4HPAcuA44GzJB3fMNky4NjUrQaumOZymnWNY97qqpU99JOATRHxSETsBm4AVjZMsxK4Jgp3AAdJ8llKqyvHvNVSKydFFwFbSp+3Aie3MM0i4CX34ktaTbE3AzAqabwzn/Ml7WihbP1qPtBX9SNpvFFHdeDruh3z84EdE6xjneQSmz1fj3ZivpWE3myp0cY0RMSVwJWTfqG0ISKWtlC2vuT66biuxnxO2zOXdanrerTS5LIVOLL0+QhgWxvTmNWFY95qqZWEfhdwrKSjJe0PrALWN0yzHjg7nfk/BXgqIqb+sk6zanDMWy1N2uQSEXsknQ/cBMwEroqI+yWdl8avBW4ElgObgGeAc/exXJM2y/Q5108H9SDmc9qeuaxLLddDEXs1+5mZWQ35TlEzs0w4oZuZZaJSCX2y2637haTNkn4k6W5JG9KwQyTdIumh9Pfg0vR/kupsSNLpvSu5TVXdYr7OsSnpKknbJd1XGjblsktakupgU3r8Q3VuIIiISnQUJ58eBn4V2B+4Bzi+1+XqUV1sBuY3DPtz4MLUfyFwaeo/PtXVbODoVIcze70O7lrazrWL+TrHJvAm4ETgvn0pO/AD4I0U9yJ8G1jW6+0y1lVpD72V26372Urg6tR/NfB7peE3RMRzEfFTiqsuTup+8awNucR8LWIzIm4DnmgYPKWyp8c7vDwivh9Fdr+mNE/PVSmhj3crdT8K4GZJG9Ot4wALIl3nnP4emoa73uqrjtsut9icatkXpf7G4ZVQpRdctHQrdZ/4rYjYJulQ4BZJD04wreutvuq47folNscre6XXqUp76L6VOomIbenvduAbFIepj489zS/93Z4md73VV+22XYaxOdWyb039jcMroUoJvZXbrbMnaY6kuWP9wNuA+yjq4pw02TnA36X+9cAqSbMlHU3xfO4fdLfU1qZaxXymsTmlsqdmmRFJp6SrW84uzdNzlWlyiXFut+5xsXphAfCNdCXUfsB1EfEdSXcBX5P0R8DPgTMBorgl/WvAA8Ae4IMR8Xxvim5TUcOYr3VsSroeGKB4PPdW4OPAp5h62T8ArANeRnGVy7e7uBoT8q3/ZmaZqFKTi5mZ7QMndDOzTDihm5llwgndzCwTTuhmZplwQjczy4QTuplZJv4/j9zKROHNEZ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_text = pd.concat([X_train_text, X_test_text])\n",
    "\n",
    "train_length = train_text.copy()\n",
    "\n",
    "for col in train_length.columns:\n",
    "    train_length[col] = train_length[col].apply(len)\n",
    "\n",
    "for col in train_length.columns:\n",
    "    d, v = np.histogram(train_length[col])\n",
    "    c = np.cumsum(d)/train_length.shape[0]\n",
    "    print (pd.DataFrame({col : v[1:], 'CDF' : c}), \"\\n\") \n",
    "\n",
    "    # Exclude the starting value of bins so that the length of density and values match, \n",
    "    # the resulting data frame is in the format of: (ending value, CDF)\n",
    "\n",
    "train_length.hist(density = True, cumulative = True, label='CDF',\n",
    "             histtype = 'step', alpha=0.8, color = 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a51a36fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_pad_len = 63\n",
    "summary_pad_len = 407\n",
    "description_pad_len = 737 # increased to 737 fom 735\n",
    "amenities_pad_len = 402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d91aa653",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start embedding process for 5127 words.\n",
      "Created embedding matrix of shape (5128, 50) in 0.0009328206380208333 min \n",
      "Encountered 1110 out-of-vocabulary words.\n",
      "Start embedding process for 16292 words.\n",
      "Created embedding matrix of shape (16293, 50) in 0.004114282131195068 min \n",
      "Encountered 4089 out-of-vocabulary words.\n",
      "Start embedding process for 28434 words.\n",
      "Created embedding matrix of shape (28435, 50) in 0.0036977887153625487 min \n",
      "Encountered 9822 out-of-vocabulary words.\n",
      "Start embedding process for 275 words.\n",
      "Created embedding matrix of shape (276, 50) in 0.00016643206278483074 min \n",
      "Encountered 2 out-of-vocabulary words.\n"
     ]
    }
   ],
   "source": [
    "# name\n",
    "name_tokenizer = Tokenizer(oov_token = 1, filters = '!\"#$%&()*+,-.:;<=>?@[\\\\]^`{|}~\\t\\n', lower = False)\n",
    "name_tokenizer.fit_on_texts(train_text.name)\n",
    "train_name_tokens = name_tokenizer.texts_to_sequences(train_text.name)\n",
    "test_name_tokens = name_tokenizer.texts_to_sequences(test_text.name)\n",
    "\n",
    "# summary\n",
    "summary_tokenizer = Tokenizer(oov_token = 1, filters = '!\"#$%&()*+,-.:;<=>?@[\\\\]^`{|}~\\t\\n', lower = False)\n",
    "summary_tokenizer.fit_on_texts(train_text.summary)\n",
    "train_summary_tokens = summary_tokenizer.texts_to_sequences(train_text.summary)\n",
    "test_summary_tokens = summary_tokenizer.texts_to_sequences(test_text.summary)\n",
    "\n",
    "# description\n",
    "description_tokenizer = Tokenizer(oov_token = 1, filters = '!\"#$%&()*+,-.:;<=>?@[\\\\]^`{|}~\\t\\n', lower = False)\n",
    "description_tokenizer.fit_on_texts(train_text.description)\n",
    "train_description_tokens = description_tokenizer.texts_to_sequences(train_text.description)\n",
    "test_description_tokens = description_tokenizer.texts_to_sequences(test_text.description)\n",
    "\n",
    "# amenities\n",
    "amenities_tokenizer = Tokenizer(oov_token = 1, filters = '!\"#$%&()*+,-.:;<=>?@[\\\\]^`{|}~\\t\\n', lower = False)\n",
    "amenities_tokenizer.fit_on_texts(train_text.amenities)\n",
    "train_amenities_tokens = amenities_tokenizer.texts_to_sequences(train_text.amenities)\n",
    "test_amenities_tokens = amenities_tokenizer.texts_to_sequences(test_text.amenities)\n",
    "\n",
    "# padding the sequences\n",
    "\n",
    "padded_train_name = pad_sequences(train_name_tokens, name_pad_len)\n",
    "padded_test_name = pad_sequences(test_name_tokens, name_pad_len)\n",
    "\n",
    "padded_train_summary = pad_sequences(train_summary_tokens, summary_pad_len)\n",
    "padded_test_summary = pad_sequences(test_summary_tokens, summary_pad_len)\n",
    "\n",
    "padded_train_description = pad_sequences(train_description_tokens, description_pad_len)\n",
    "padded_test_description = pad_sequences(test_description_tokens, description_pad_len)\n",
    "\n",
    "padded_train_amenities = pad_sequences(train_amenities_tokens, amenities_pad_len)\n",
    "padded_test_amenities = pad_sequences(test_amenities_tokens, amenities_pad_len)\n",
    "\n",
    "name_vocab_size = len(name_tokenizer.word_index) + 1\n",
    "summary_vocab_size = len(summary_tokenizer.word_index) + 1\n",
    "description_vocab_size = len(description_tokenizer.word_index) + 1\n",
    "amenities_vocab_size = len(amenities_tokenizer.word_index) + 1\n",
    "\n",
    "# Load GloVe embeddings\n",
    "glove = 'glove.6B.50d.txt'\n",
    "\n",
    "glove_index = {}\n",
    "start = time.time()\n",
    "i = 0\n",
    "with open(glove, 'r', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        glove_index[word] = coefs\n",
    "        i += 1\n",
    "        #if i % 50000 == 0:\n",
    "            #print('Read {} lines of embeddings in {} sec.'.format(i, time.time()-start))\n",
    "\n",
    "name_glove_weights, _ = get_embedding_matrix(name_tokenizer, glove_index, name_vocab_size)\n",
    "summary_glove_weights, _ = get_embedding_matrix(summary_tokenizer, glove_index, summary_vocab_size)\n",
    "description_glove_weights, _ = get_embedding_matrix(description_tokenizer, glove_index, description_vocab_size)\n",
    "amenities_glove_weights, _ = get_embedding_matrix(amenities_tokenizer, glove_index, amenities_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6cee63e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 63)]         0           []                               \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, 407)]        0           []                               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 737)]        0           []                               \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 402)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 63, 50)       256400      ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 407, 50)      814650      ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, 737, 50)      1421750     ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)        (None, 402, 50)      13800       ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " gru_5 (GRU)                    (None, 25)           5775        ['embedding_5[0][0]']            \n",
      "                                                                                                  \n",
      " gru_6 (GRU)                    (None, 100)          45600       ['embedding_6[0][0]']            \n",
      "                                                                                                  \n",
      " gru_7 (GRU)                    (None, 100)          45600       ['embedding_7[0][0]']            \n",
      "                                                                                                  \n",
      " gru_8 (GRU)                    (None, 100)          45600       ['embedding_8[0][0]']            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1)            26          ['gru_5[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 1)            101         ['gru_6[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1)            101         ['gru_7[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1)            101         ['gru_8[0][0]']                  \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 17)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 21)           0           ['dense_13[0][0]',               \n",
      "                                                                  'dense_14[0][0]',               \n",
      "                                                                  'dense_15[0][0]',               \n",
      "                                                                  'dense_16[0][0]',               \n",
      "                                                                  'input_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 256)          5632        ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 128)          32896       ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 64)           8256        ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 1)            65          ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,696,353\n",
      "Trainable params: 2,696,353\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_name = Input(shape=(name_pad_len, ))\n",
    "name_embeddings = Embedding(name_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(name_glove_weights),\n",
    "                     input_length = name_pad_len, trainable = True)(input_name) \n",
    "GRU_name = GRU(25)(name_embeddings)\n",
    "dense_name = Dense(1, activation = \"linear\")(GRU_name)\n",
    "\n",
    "\n",
    "input_summary = Input(shape = (summary_pad_len, ))\n",
    "summary_embeddings = Embedding(summary_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(summary_glove_weights),\n",
    "                     input_length = summary_pad_len, trainable = True)(input_summary)\n",
    "GRU_summary = GRU(100)(summary_embeddings)\n",
    "dense_summary = Dense(1, activation = \"linear\")(GRU_summary)\n",
    "\n",
    "\n",
    "input_description = Input(shape = (description_pad_len, ))\n",
    "description_embeddings = Embedding(description_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(description_glove_weights),\n",
    "                     input_length = description_pad_len, trainable = True)(input_description)\n",
    "GRU_description = GRU(100)(description_embeddings)\n",
    "dense_description = Dense(1, activation = \"linear\")(GRU_description)\n",
    "\n",
    "\n",
    "input_amenities = Input(shape = (amenities_pad_len, ))\n",
    "amenities_embeddings = Embedding(amenities_vocab_size, output_dim=50,\n",
    "                     embeddings_initializer = Constant(amenities_glove_weights),\n",
    "                     input_length = description_pad_len, trainable = True)(input_amenities)\n",
    "GRU_amenities = GRU(100)(amenities_embeddings)\n",
    "dense_amenities = Dense(1, activation = \"linear\")(GRU_amenities)\n",
    "\n",
    "\n",
    "input_nontext = Input(shape=(train.shape[1],))\n",
    "\n",
    "\n",
    "# Concatenate\n",
    "concat = concatenate([dense_name, dense_summary, dense_description, dense_amenities, input_nontext])\n",
    "dense_full1 = Dense(256, activation = \"relu\")(concat)\n",
    "dense_full2 = Dense(128, activation = \"relu\")(dense_full1)\n",
    "dense_full3 = Dense(64, activation = \"relu\")(dense_full2)\n",
    "output_layer = Dense(1, activation = \"linear\")(dense_full3)\n",
    "\n",
    "model = Model(inputs=[input_name, input_summary, input_description, input_amenities, input_nontext], outputs = output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bd540bb3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "324/324 [==============================] - 3499s 11s/step - loss: 3137.8613 - mse: 3137.8613 - mae: 34.7104 - val_loss: 2760.3872 - val_mse: 2760.3872 - val_mae: 33.2894\n",
      "Epoch 2/25\n",
      "324/324 [==============================] - 3430s 11s/step - loss: 2528.3140 - mse: 2528.3140 - mae: 31.0423 - val_loss: 2664.8008 - val_mse: 2664.8008 - val_mae: 31.3687\n",
      "Epoch 3/25\n",
      "324/324 [==============================] - 3431s 11s/step - loss: 2216.3806 - mse: 2216.3806 - mae: 29.1086 - val_loss: 2766.3455 - val_mse: 2766.3455 - val_mae: 31.6267\n",
      "Epoch 4/25\n",
      "324/324 [==============================] - 3434s 11s/step - loss: 1985.3951 - mse: 1985.3951 - mae: 27.5033 - val_loss: 2754.1509 - val_mse: 2754.1509 - val_mae: 31.5457\n",
      "Epoch 5/25\n",
      "324/324 [==============================] - ETA: 0s - loss: 1841.8385 - mse: 1841.8385 - mae: 26.5433 Restoring model weights from the end of the best epoch: 2.\n",
      "324/324 [==============================] - 3417s 11s/step - loss: 1841.8385 - mse: 1841.8385 - mae: 26.5433 - val_loss: 2812.0457 - val_mse: 2812.0457 - val_mae: 31.4987\n",
      "Epoch 5: early stopping\n",
      "17211.206006765366\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.01) \n",
    "\n",
    "model.compile(optimizer = opt, loss='mean_squared_error', metrics=['mse', 'mae'])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 25\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=0.01, restore_best_weights=True)]\n",
    "\n",
    "story = model.fit([padded_train_name, padded_train_summary, padded_train_description, padded_train_amenities, train], y,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs,\n",
    "                    verbose = 1,\n",
    "                    validation_split = 0.25,\n",
    "                  callbacks = callbacks) \n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88519c33",
   "metadata": {},
   "source": [
    "Finally, the predictions are produced and concatenate with test_listing_id into the format required for submission and saved as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cd716262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "931/931 [==============================] - 424s 454ms/step\n"
     ]
    }
   ],
   "source": [
    "gru_test_prediction = model.predict([padded_test_name, padded_test_summary, padded_test_description, padded_test_amenities, test])\n",
    "gru_test_prediction = pd.DataFrame(gru_test_prediction, columns = [\"price\"])\n",
    "gru_test_result = pd.concat([test_listing_id, gru_test_prediction], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36a030f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_test_result.to_csv(\"C:/Users/felix/OneDrive/Desktop/ADAMS kaggle/gru_test_prediction.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87648e9d",
   "metadata": {},
   "source": [
    "# 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41190662",
   "metadata": {},
   "source": [
    "Through this assignment, it could be observed that the inclusion of NLP techniques and neural networks improved the prediction of price using non-text and text features.\n",
    "\n",
    "It is clear that there are models that could perform better than the one shown here, for the improvement of data preparation, the non-english text could be translated into english instead of simply discarding them (in the case of reviews) or replacing them with 'non-english' (those in train data). The images from url links could also be included by using Convolutional Neural Network (CNN). Both Longtitude anf Latitude could also be used to determine the more exact location of the airbnb listing and whether it is a more expensive are (which can increase price prediction).\n",
    "\n",
    "Given the time and computational power constraint, not all possibilities are being explored but overall it has been a great learning experience, learning the application of NLP techniques and Neural Networks working with real world data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
